#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºçš„å¤šå› å­æ¨¡å‹ç³»ç»Ÿ
è§£å†³æ•°æ®ç¼ºå¤±å’Œæ¨¡å‹è®­ç»ƒé—®é¢˜çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

ä¸»è¦åŠŸèƒ½ï¼š
1. æ‰¹é‡è®¡ç®—å†å²å› å­æ•°æ®
2. ä¿®å¤æ•°æ®åŒ¹é…é—®é¢˜
3. æä¾›å®Œæ•´çš„æœºå™¨å­¦ä¹ è®­ç»ƒæµç¨‹
4. åŒ…å«æ•°æ®éªŒè¯å’Œé”™è¯¯å¤„ç†
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.model_selection import train_test_split, cross_val_score, TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_regression
import xgboost as xgb
import lightgbm as lgb

# å¯è§†åŒ–åº“
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ•°æ®åº“ç›¸å…³
from app import create_app
from app.extensions import db
from app.models import (
    StockDailyHistory, StockDailyBasic, StockFactor, StockMoneyflow, 
    StockCyqPerf, FactorDefinition, FactorValues, MLModelDefinition, 
    MLPredictions, StockBasic
)
from app.services.factor_engine import FactorEngine
from app.services.ml_models import MLModelManager

class EnhancedMultiFactorSystem:
    """å¢å¼ºçš„å¤šå› å­æ¨¡å‹ç³»ç»Ÿ"""
    
    def __init__(self):
        self.app = create_app()
        self.factor_engine = None
        self.ml_manager = None
        self.evaluation_results = {}
        
        print("ğŸš€ åˆå§‹åŒ–å¢å¼ºå¤šå› å­æ¨¡å‹ç³»ç»Ÿ...")
        print("=" * 80)
        
    def initialize_services(self):
        """åˆå§‹åŒ–æœåŠ¡"""
        with self.app.app_context():
            self.factor_engine = FactorEngine()
            self.ml_manager = MLModelManager()
            print("âœ… æœåŠ¡åˆå§‹åŒ–å®Œæˆ")
    
    def diagnose_data_issues(self):
        """è¯Šæ–­æ•°æ®é—®é¢˜"""
        print("\nğŸ” è¯Šæ–­æ•°æ®é—®é¢˜...")
        print("=" * 60)
        
        with self.app.app_context():
            try:
                # æ£€æŸ¥åŸºç¡€æ•°æ®
                history_count = StockDailyHistory.query.count()
                basic_count = StockDailyBasic.query.count()
                factor_count = FactorValues.query.count()
                
                print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
                print(f"   å†å²ä»·æ ¼æ•°æ®: {history_count:,} æ¡")
                print(f"   åŸºæœ¬é¢æ•°æ®: {basic_count:,} æ¡")
                print(f"   å› å­æ•°æ®: {factor_count:,} æ¡")
                
                # æ£€æŸ¥æ—¥æœŸèŒƒå›´
                if history_count > 0:
                    min_date = db.session.query(db.func.min(StockDailyHistory.trade_date)).scalar()
                    max_date = db.session.query(db.func.max(StockDailyHistory.trade_date)).scalar()
                    print(f"   ä»·æ ¼æ•°æ®æ—¥æœŸèŒƒå›´: {min_date} è‡³ {max_date}")
                
                if factor_count > 0:
                    factor_min_date = db.session.query(db.func.min(FactorValues.trade_date)).scalar()
                    factor_max_date = db.session.query(db.func.max(FactorValues.trade_date)).scalar()
                    print(f"   å› å­æ•°æ®æ—¥æœŸèŒƒå›´: {factor_min_date} è‡³ {factor_max_date}")
                    
                    # æ£€æŸ¥å› å­ç±»å‹
                    factor_types = db.session.query(FactorValues.factor_id).distinct().all()
                    factor_ids = [f[0] for f in factor_types]
                    print(f"   å¯ç”¨å› å­: {factor_ids}")
                
                # è¯Šæ–­é—®é¢˜ - ä¿®æ”¹é€»è¾‘ï¼Œæ›´å®½æ¾çš„æ¡ä»¶
                issues = []
                if factor_count < 10000:  # éœ€è¦æ›´å¤šå› å­æ•°æ®
                    issues.append("å› å­æ•°æ®ä¸è¶³ï¼Œéœ€è¦è®¡ç®—æ›´å¤šå› å­")
                if len(db.session.query(FactorValues.factor_id).distinct().all()) < 5:
                    issues.append("å› å­ç§ç±»ä¸è¶³ï¼Œéœ€è¦è®¡ç®—æ›´å¤šç±»å‹çš„å› å­")
                
                if issues:
                    print(f"\nâš ï¸  å‘ç°é—®é¢˜: {', '.join(issues)}")
                    return False
                else:
                    print(f"\nâœ… æ•°æ®æ£€æŸ¥é€šè¿‡")
                    return True
                    
            except Exception as e:
                print(f"âŒ è¯Šæ–­å¤±è´¥: {e}")
                return False
    
    def calculate_comprehensive_factors(self, start_date='2025-05-01', end_date='2025-05-23'):
        """è®¡ç®—å…¨é¢çš„å› å­æ•°æ®"""
        print(f"\nğŸ”§ è®¡ç®—å…¨é¢å› å­æ•°æ® ({start_date} è‡³ {end_date})...")
        print("=" * 60)
        
        with self.app.app_context():
            try:
                # è·å–æ‰€æœ‰è‚¡ç¥¨ä»£ç 
                stocks = StockBasic.query.limit(100).all()  # å…ˆå¤„ç†100åªè‚¡ç¥¨
                ts_codes = [stock.ts_code for stock in stocks]
                print(f"ğŸ“ˆ å¤„ç†è‚¡ç¥¨æ•°é‡: {len(ts_codes)}")
                
                # å®šä¹‰è¦è®¡ç®—çš„å› å­
                factors_to_calculate = [
                    'momentum_5d',      # 5æ—¥åŠ¨é‡
                    'momentum_20d',     # 20æ—¥åŠ¨é‡
                    'volatility_20d',   # 20æ—¥æ³¢åŠ¨ç‡
                    'volume_ratio_20d', # æˆäº¤é‡æ¯”ç‡
                    'price_to_ma20',    # ä»·æ ¼ç›¸å¯¹MA20
                    'pe_percentile',    # PEç™¾åˆ†ä½
                    'pb_percentile',    # PBç™¾åˆ†ä½
                ]
                
                # ç”Ÿæˆæ—¥æœŸåºåˆ—
                date_range = pd.date_range(start=start_date, end=end_date, freq='D')
                trading_dates = []
                
                # ç­›é€‰äº¤æ˜“æ—¥
                for date in date_range:
                    date_str = date.strftime('%Y-%m-%d')
                    count = StockDailyHistory.query.filter_by(trade_date=date_str).count()
                    if count > 0:
                        trading_dates.append(date_str)
                
                print(f"ğŸ“… äº¤æ˜“æ—¥æ•°é‡: {len(trading_dates)}")
                
                total_calculated = 0
                
                # æŒ‰æ—¥æœŸè®¡ç®—å› å­
                for trade_date in trading_dates:
                    print(f"\nğŸ“Š è®¡ç®— {trade_date} çš„å› å­...")
                    
                    for factor_id in factors_to_calculate:
                        try:
                            # è®¡ç®—å› å­
                            result_df = self.factor_engine.calculate_factor(
                                factor_id, ts_codes, trade_date, trade_date
                            )
                            
                            if not result_df.empty:
                                # ä¿å­˜å› å­å€¼
                                success = self.factor_engine.save_factor_values(result_df)
                                if success:
                                    total_calculated += len(result_df)
                                    print(f"   âœ… {factor_id}: {len(result_df)} æ¡è®°å½•")
                                else:
                                    print(f"   âŒ {factor_id}: ä¿å­˜å¤±è´¥")
                            else:
                                print(f"   âš ï¸  {factor_id}: æ— æ•°æ®")
                                
                        except Exception as e:
                            print(f"   âŒ {factor_id}: è®¡ç®—å¤±è´¥ - {e}")
                
                print(f"\nâœ… å› å­è®¡ç®—å®Œæˆï¼Œå…±è®¡ç®— {total_calculated} æ¡å› å­æ•°æ®")
                return total_calculated > 0
                
            except Exception as e:
                print(f"âŒ å› å­è®¡ç®—å¤±è´¥: {e}")
                return False
    
    def create_enhanced_models(self):
        """åˆ›å»ºå¢å¼ºçš„æœºå™¨å­¦ä¹ æ¨¡å‹"""
        print(f"\nğŸ¤– åˆ›å»ºå¢å¼ºæœºå™¨å­¦ä¹ æ¨¡å‹...")
        print("=" * 60)
        
        with self.app.app_context():
            try:
                # æ£€æŸ¥å¯ç”¨å› å­
                available_factors = db.session.query(FactorValues.factor_id).distinct().all()
                factor_ids = [f[0] for f in available_factors]
                
                if len(factor_ids) < 2:
                    print(f"âš ï¸  å¯ç”¨å› å­ä¸è¶³ ({len(factor_ids)}ä¸ª)ï¼Œæ— æ³•åˆ›å»ºæ¨¡å‹")
                    return False
                
                print(f"ğŸ“Š å¯ç”¨å› å­: {factor_ids}")
                
                # å¦‚æœå› å­ä¸è¶³ï¼Œåˆ›å»ºç®€åŒ–æ¨¡å‹
                if len(factor_ids) < 5:
                    print("âš ï¸  å› å­æ•°é‡è¾ƒå°‘ï¼Œåˆ›å»ºç®€åŒ–æ¼”ç¤ºæ¨¡å‹")
                    model_configs = [
                        {
                            'model_id': 'simple_demo_model',
                            'model_name': 'ç®€åŒ–æ¼”ç¤ºæ¨¡å‹',
                            'model_type': 'random_forest',
                            'factor_list': factor_ids,
                            'target_type': 'simulated_return',  # ä½¿ç”¨æ¨¡æ‹Ÿç›®æ ‡å˜é‡
                            'model_params': {
                                'n_estimators': 50,
                                'max_depth': 5,
                                'min_samples_split': 10,
                                'random_state': 42
                            }
                        }
                    ]
                else:
                    # æ¨¡å‹é…ç½®
                    model_configs = [
                        {
                            'model_id': 'enhanced_rf_model',
                            'model_name': 'å¢å¼ºéšæœºæ£®æ—æ¨¡å‹',
                            'model_type': 'random_forest',
                            'factor_list': factor_ids,
                            'target_type': 'return_5d',
                            'model_params': {
                                'n_estimators': 100,
                                'max_depth': 10,
                                'min_samples_split': 5,
                                'random_state': 42
                            }
                        },
                        {
                            'model_id': 'enhanced_xgb_model',
                            'model_name': 'å¢å¼ºXGBoostæ¨¡å‹',
                            'model_type': 'xgboost',
                            'factor_list': factor_ids,
                            'target_type': 'return_5d',
                            'model_params': {
                                'n_estimators': 100,
                                'max_depth': 6,
                                'learning_rate': 0.1,
                                'random_state': 42
                            }
                        }
                    ]
                
                created_models = []
                
                for config in model_configs:
                    try:
                        # åˆ é™¤å·²å­˜åœ¨çš„æ¨¡å‹
                        existing = MLModelDefinition.query.filter_by(model_id=config['model_id']).first()
                        if existing:
                            db.session.delete(existing)
                            db.session.commit()
                        
                        # åˆ›å»ºæ–°æ¨¡å‹
                        success = self.ml_manager.create_model_definition(**config)
                        if success:
                            created_models.append(config['model_id'])
                            print(f"   âœ… åˆ›å»ºæ¨¡å‹: {config['model_name']}")
                        else:
                            print(f"   âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {config['model_name']}")
                            
                    except Exception as e:
                        print(f"   âŒ åˆ›å»ºæ¨¡å‹å¼‚å¸¸: {config['model_name']} - {e}")
                
                print(f"\nâœ… æˆåŠŸåˆ›å»º {len(created_models)} ä¸ªæ¨¡å‹")
                return len(created_models) > 0
                
            except Exception as e:
                print(f"âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
                return False
    
    def train_models_with_validation(self):
        """è®­ç»ƒæ¨¡å‹å¹¶è¿›è¡ŒéªŒè¯"""
        print(f"\nğŸ¯ è®­ç»ƒæ¨¡å‹å¹¶éªŒè¯...")
        print("=" * 60)
        
        with self.app.app_context():
            try:
                # è·å–æ‰€æœ‰æ¨¡å‹
                models = MLModelDefinition.query.filter_by(is_active=True).all()
                
                if not models:
                    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹å®šä¹‰")
                    return False
                
                training_results = {}
                
                for model in models:
                    print(f"\nğŸ”„ è®­ç»ƒæ¨¡å‹: {model.model_name}")
                    
                    try:
                        # æ£€æŸ¥æ•°æ®å¯ç”¨æ€§
                        factor_count = FactorValues.query.filter(
                            FactorValues.factor_id.in_(model.factor_list)
                        ).count()
                        
                        if factor_count < 100:
                            print(f"   âš ï¸  æ•°æ®ä¸è¶³ ({factor_count} æ¡)ï¼Œè·³è¿‡è®­ç»ƒ")
                            continue
                        
                        # è·å–æ—¥æœŸèŒƒå›´
                        min_date = db.session.query(db.func.min(FactorValues.trade_date)).scalar()
                        max_date = db.session.query(db.func.max(FactorValues.trade_date)).scalar()
                        
                        print(f"   ğŸ“… è®­ç»ƒæ—¥æœŸèŒƒå›´: {min_date} è‡³ {max_date}")
                        
                        # è®­ç»ƒæ¨¡å‹
                        result = self.ml_manager.train_model(
                            model.model_id, str(min_date), str(max_date)
                        )
                        
                        if result['success']:
                            training_results[model.model_id] = result
                            print(f"   âœ… è®­ç»ƒæˆåŠŸ")
                            print(f"   ğŸ“Š æ ·æœ¬æ•°é‡: {result.get('sample_count', 'N/A')}")
                            print(f"   ğŸ“ˆ RÂ²åˆ†æ•°: {result.get('metrics', {}).get('r2_score', 'N/A'):.4f}")
                        else:
                            print(f"   âŒ è®­ç»ƒå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                            
                    except Exception as e:
                        print(f"   âŒ è®­ç»ƒå¼‚å¸¸: {e}")
                
                print(f"\nâœ… å®Œæˆæ¨¡å‹è®­ç»ƒï¼ŒæˆåŠŸè®­ç»ƒ {len(training_results)} ä¸ªæ¨¡å‹")
                self.evaluation_results = training_results
                return len(training_results) > 0
                
            except Exception as e:
                print(f"âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
                return False
    
    def generate_predictions(self, trade_date='2025-05-23'):
        """ç”Ÿæˆé¢„æµ‹ç»“æœ"""
        print(f"\nğŸ”® ç”Ÿæˆé¢„æµ‹ç»“æœ ({trade_date})...")
        print("=" * 60)
        
        with self.app.app_context():
            try:
                # è·å–å·²è®­ç»ƒçš„æ¨¡å‹
                models = MLModelDefinition.query.filter_by(is_active=True).all()
                trained_models = []
                
                for model in models:
                    if model.model_id in self.evaluation_results:
                        trained_models.append(model)
                
                if not trained_models:
                    print("âŒ æ²¡æœ‰å·²è®­ç»ƒçš„æ¨¡å‹")
                    return False
                
                prediction_results = {}
                
                for model in trained_models:
                    print(f"\nğŸ¯ ç”Ÿæˆé¢„æµ‹: {model.model_name}")
                    
                    try:
                        # ç”Ÿæˆé¢„æµ‹
                        predictions_df = self.ml_manager.predict(model.model_id, trade_date)
                        
                        if not predictions_df.empty:
                            # ä¿å­˜é¢„æµ‹ç»“æœ
                            success = self.ml_manager.save_predictions(predictions_df)
                            if success:
                                prediction_results[model.model_id] = predictions_df
                                print(f"   âœ… é¢„æµ‹æˆåŠŸ: {len(predictions_df)} åªè‚¡ç¥¨")
                                
                                # æ˜¾ç¤ºå‰5åé¢„æµ‹ç»“æœ
                                top_5 = predictions_df.nlargest(5, 'predicted_return')
                                print(f"   ğŸ“ˆ é¢„æµ‹æ”¶ç›Šå‰5å:")
                                for _, row in top_5.iterrows():
                                    print(f"      {row['ts_code']}: {row['predicted_return']:.4f}")
                            else:
                                print(f"   âŒ ä¿å­˜é¢„æµ‹å¤±è´¥")
                        else:
                            print(f"   âš ï¸  é¢„æµ‹ç»“æœä¸ºç©º")
                            
                    except Exception as e:
                        print(f"   âŒ é¢„æµ‹å¼‚å¸¸: {e}")
                
                print(f"\nâœ… å®Œæˆé¢„æµ‹ç”Ÿæˆï¼ŒæˆåŠŸé¢„æµ‹ {len(prediction_results)} ä¸ªæ¨¡å‹")
                return len(prediction_results) > 0
                
            except Exception as e:
                print(f"âŒ é¢„æµ‹ç”Ÿæˆå¤±è´¥: {e}")
                return False
    
    def create_comprehensive_report(self):
        """åˆ›å»ºç»¼åˆæŠ¥å‘Š"""
        print(f"\nğŸ“Š ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š...")
        print("=" * 60)
        
        with self.app.app_context():
            try:
                report = {
                    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'data_summary': {},
                    'model_performance': {},
                    'predictions_summary': {}
                }
                
                # æ•°æ®æ‘˜è¦
                history_count = StockDailyHistory.query.count()
                factor_count = FactorValues.query.count()
                model_count = MLModelDefinition.query.filter_by(is_active=True).count()
                prediction_count = MLPredictions.query.count()
                
                report['data_summary'] = {
                    'history_records': history_count,
                    'factor_records': factor_count,
                    'active_models': model_count,
                    'prediction_records': prediction_count
                }
                
                # æ¨¡å‹æ€§èƒ½
                for model_id, results in self.evaluation_results.items():
                    model = MLModelDefinition.query.filter_by(model_id=model_id).first()
                    if model:
                        report['model_performance'][model_id] = {
                            'model_name': model.model_name,
                            'model_type': model.model_type,
                            'success': results['success'],
                            'metrics': results.get('metrics', {}),
                            'sample_count': results.get('sample_count', 0)
                        }
                
                # é¢„æµ‹æ‘˜è¦
                latest_predictions = MLPredictions.query.order_by(
                    MLPredictions.trade_date.desc()
                ).limit(10).all()
                
                if latest_predictions:
                    report['predictions_summary'] = {
                        'latest_date': str(latest_predictions[0].trade_date),
                        'prediction_count': len(latest_predictions),
                        'top_predictions': [
                            {
                                'ts_code': pred.ts_code,
                                'predicted_return': float(pred.predicted_return),
                                'model_id': pred.model_id
                            }
                            for pred in latest_predictions[:5]
                        ]
                    }
                
                # ä¿å­˜æŠ¥å‘Š
                report_file = f"enhanced_multifactor_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
                
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write("å¢å¼ºå¤šå› å­æ¨¡å‹ç³»ç»Ÿè¯„ä¼°æŠ¥å‘Š\n")
                    f.write("=" * 50 + "\n\n")
                    
                    f.write(f"ç”Ÿæˆæ—¶é—´: {report['timestamp']}\n\n")
                    
                    f.write("æ•°æ®æ‘˜è¦:\n")
                    for key, value in report['data_summary'].items():
                        f.write(f"  {key}: {value:,}\n")
                    f.write("\n")
                    
                    f.write("æ¨¡å‹æ€§èƒ½:\n")
                    for model_id, perf in report['model_performance'].items():
                        f.write(f"  {perf['model_name']} ({model_id}):\n")
                        f.write(f"    ç±»å‹: {perf['model_type']}\n")
                        f.write(f"    è®­ç»ƒçŠ¶æ€: {'æˆåŠŸ' if perf['success'] else 'å¤±è´¥'}\n")
                        f.write(f"    æ ·æœ¬æ•°é‡: {perf['sample_count']:,}\n")
                        if perf['metrics']:
                            for metric, value in perf['metrics'].items():
                                if isinstance(value, (int, float)):
                                    f.write(f"    {metric}: {value:.4f}\n")
                        f.write("\n")
                    
                    if report['predictions_summary']:
                        f.write("é¢„æµ‹æ‘˜è¦:\n")
                        f.write(f"  æœ€æ–°é¢„æµ‹æ—¥æœŸ: {report['predictions_summary']['latest_date']}\n")
                        f.write(f"  é¢„æµ‹æ•°é‡: {report['predictions_summary']['prediction_count']}\n")
                        f.write("  é¢„æµ‹æ”¶ç›Šå‰5å:\n")
                        for pred in report['predictions_summary']['top_predictions']:
                            f.write(f"    {pred['ts_code']}: {pred['predicted_return']:.4f}\n")
                
                print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
                
                # æ§åˆ¶å°è¾“å‡ºæ‘˜è¦
                print(f"\nğŸ“‹ ç³»ç»ŸçŠ¶æ€æ‘˜è¦:")
                print(f"   å†å²æ•°æ®: {history_count:,} æ¡")
                print(f"   å› å­æ•°æ®: {factor_count:,} æ¡")
                print(f"   æ´»è·ƒæ¨¡å‹: {model_count} ä¸ª")
                print(f"   é¢„æµ‹è®°å½•: {prediction_count:,} æ¡")
                print(f"   æˆåŠŸè®­ç»ƒ: {len(self.evaluation_results)} ä¸ªæ¨¡å‹")
                
                return True
                
            except Exception as e:
                print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
                return False
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„å¤šå› å­æ¨¡å‹æµç¨‹"""
        print("ğŸš€ å¯åŠ¨å¢å¼ºå¤šå› å­æ¨¡å‹ç³»ç»Ÿå®Œæ•´æµç¨‹")
        print("=" * 80)
        
        try:
            # 1. åˆå§‹åŒ–æœåŠ¡
            self.initialize_services()
            
            # 2. è¯Šæ–­æ•°æ®é—®é¢˜
            data_ok = self.diagnose_data_issues()
            
            # 3. è®¡ç®—å› å­æ•°æ®ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if not data_ok:
                print("\nğŸ”§ æ•°æ®ä¸è¶³ï¼Œå¼€å§‹è®¡ç®—å› å­æ•°æ®...")
                factor_ok = self.calculate_comprehensive_factors()
                if not factor_ok:
                    print("âŒ å› å­è®¡ç®—å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                    return False
            
            # 4. åˆ›å»ºæ¨¡å‹
            model_ok = self.create_enhanced_models()
            if not model_ok:
                print("âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return False
            
            # 5. è®­ç»ƒæ¨¡å‹
            train_ok = self.train_models_with_validation()
            if not train_ok:
                print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return False
            
            # 6. ç”Ÿæˆé¢„æµ‹
            pred_ok = self.generate_predictions()
            if not pred_ok:
                print("âŒ é¢„æµ‹ç”Ÿæˆå¤±è´¥")
            
            # 7. ç”ŸæˆæŠ¥å‘Š
            report_ok = self.create_comprehensive_report()
            
            print("\nğŸ‰ å¢å¼ºå¤šå› å­æ¨¡å‹ç³»ç»Ÿæµç¨‹å®Œæˆï¼")
            print("=" * 80)
            
            return True
            
        except Exception as e:
            print(f"âŒ æµç¨‹æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """ä¸»å‡½æ•°"""
    system = EnhancedMultiFactorSystem()
    success = system.run_complete_pipeline()
    
    if success:
        print("\nâœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
        print("ğŸ’¡ æ¥ä¸‹æ¥å¯ä»¥:")
        print("   1. æŸ¥çœ‹ç”Ÿæˆçš„è¯„ä¼°æŠ¥å‘Š")
        print("   2. åœ¨Webç•Œé¢ä¸­æŸ¥çœ‹æ¨¡å‹å’Œé¢„æµ‹ç»“æœ")
        print("   3. ç»§ç»­ä¼˜åŒ–æ¨¡å‹å‚æ•°")
    else:
        print("\nâŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 