#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å·¥ä½œç‰ˆæ¼”ç¤ºæœºå™¨å­¦ä¹ æ¨¡å‹
åŸºäºçœŸå®æ•°æ®åº“å­—æ®µè¿›è¡Œè‚¡ç¥¨æ”¶ç›Šé¢„æµ‹
åŒ…å«å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–æµç¨‹
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_regression
import xgboost as xgb
import lightgbm as lgb

# å¯è§†åŒ–åº“
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ•°æ®åº“è¿æ¥
import pymysql

class WorkingDemoMLModel:
    """å·¥ä½œç‰ˆæ¼”ç¤ºæœºå™¨å­¦ä¹ æ¨¡å‹"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.evaluation_results = {}
        
        # æ¨¡å‹é…ç½®
        self.model_configs = {
            'RandomForest': {
                'model': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),
                'name': 'éšæœºæ£®æ—'
            },
            'XGBoost': {
                'model': xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42),
                'name': 'XGBoostæ¢¯åº¦æå‡'
            },
            'LightGBM': {
                'model': lgb.LGBMRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbose=-1),
                'name': 'LightGBM'
            },
            'Ridge': {
                'model': Ridge(alpha=1.0, random_state=42),
                'name': 'å²­å›å½’'
            }
        }
        
        # æ•°æ®åº“è¿æ¥
        self.connection = pymysql.connect(
            host='localhost',
            user='root',
            password='root',
            database='stock_cursor',
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        print("âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“")
    
    def prepare_demo_dataset(self):
        """å‡†å¤‡æ¼”ç¤ºæ•°æ®é›†"""
        print("\nğŸ”§ å‡†å¤‡æ¼”ç¤ºæ•°æ®é›†...")
        print("=" * 80)
        
        try:
            # ä½¿ç”¨ç°æœ‰çš„è´¢åŠ¡æ•°æ®è¡¨åˆ›å»ºç‰¹å¾
            query = """
            SELECT 
                i.ts_code,
                i.end_date,
                i.revenue,
                i.operate_profit,
                i.n_income_attr_p,
                i.basic_eps,
                i.total_profit,
                i.income_tax,
                b.total_assets,
                b.total_cur_assets,
                b.total_cur_liab,
                b.total_liab,
                b.total_hldr_eqy_inc_min_int,
                c.n_cashflow_act,
                c.n_cashflow_inv_act,
                c.n_cash_flows_fnc_act,
                c.free_cashflow
            FROM stock_income_statement i
            LEFT JOIN stock_balance_sheet b ON i.ts_code = b.ts_code AND i.end_date = b.end_date
            LEFT JOIN stock_cash_flow c ON i.ts_code = c.ts_code AND i.end_date = c.end_date
            WHERE i.end_date >= '2022-12-31' 
            AND i.end_date <= '2023-12-31'
            AND i.revenue IS NOT NULL 
            AND i.revenue > 0
            AND b.total_assets IS NOT NULL 
            AND b.total_assets > 0
            ORDER BY i.ts_code, i.end_date
            LIMIT 500
            """
            
            df = pd.read_sql(query, self.connection)
            
            if df.empty:
                print("âŒ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®")
                return None
            
            print(f"ğŸ“Š è·å–åˆ° {len(df)} æ¡åŸå§‹è®°å½•")
            
            # è½¬æ¢æ•°æ®ç±»å‹
            numeric_cols = ['revenue', 'operate_profit', 'n_income_attr_p', 'basic_eps',
                           'total_profit', 'income_tax', 'total_assets', 'total_cur_assets', 
                           'total_cur_liab', 'total_liab', 'total_hldr_eqy_inc_min_int',
                           'n_cashflow_act', 'n_cashflow_inv_act', 'n_cash_flows_fnc_act', 'free_cashflow']
            
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤å…³é”®æŒ‡æ ‡ä¸ºç©ºçš„è¡Œ
            df = df.dropna(subset=['revenue', 'total_assets', 'total_cur_assets'])
            
            if df.empty:
                print("âŒ æ•°æ®æ¸…æ´—åä¸ºç©º")
                return None
            
            # å¡«å……å‰©ä½™NaNå€¼ä¸º0
            df = df.fillna(0)
            
            print(f"ğŸ“Š æ¸…æ´—åæœ‰æ•ˆè®°å½•ï¼š{len(df)} æ¡")
            
            # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡ä½œä¸ºç‰¹å¾
            print("ğŸ“Š è®¡ç®—è´¢åŠ¡æŒ‡æ ‡ç‰¹å¾...")
            
            # å®‰å…¨é™¤æ³•å‡½æ•°
            def safe_divide(a, b, default=0):
                return np.where((b != 0) & (~np.isnan(b)) & (~np.isinf(b)), a / b, default)
            
            # ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡
            df['profit_margin'] = safe_divide(df['operate_profit'], df['revenue']) * 100
            df['net_margin'] = safe_divide(df['n_income_attr_p'], df['revenue']) * 100
            df['gross_margin'] = safe_divide(df['total_profit'], df['revenue']) * 100
            
            # å¿å€ºèƒ½åŠ›æŒ‡æ ‡
            df['current_ratio'] = safe_divide(df['total_cur_assets'], df['total_cur_liab'], 1.0)
            df['debt_ratio'] = safe_divide(df['total_liab'], df['total_assets']) * 100
            df['equity_ratio'] = safe_divide(df['total_hldr_eqy_inc_min_int'], df['total_assets']) * 100
            
            # è¥è¿èƒ½åŠ›æŒ‡æ ‡
            df['asset_turnover'] = safe_divide(df['revenue'], df['total_assets'])
            df['equity_turnover'] = safe_divide(df['revenue'], df['total_hldr_eqy_inc_min_int'])
            
            # ç°é‡‘æµæŒ‡æ ‡
            df['operating_cf_ratio'] = safe_divide(df['n_cashflow_act'], df['revenue']) * 100
            df['free_cf_ratio'] = safe_divide(df['free_cashflow'], df['revenue']) * 100
            df['cf_to_debt'] = safe_divide(df['n_cashflow_act'], df['total_liab'])
            
            # ROEå’ŒROA
            df['roe'] = safe_divide(df['n_income_attr_p'], df['total_hldr_eqy_inc_min_int']) * 100
            df['roa'] = safe_divide(df['n_income_attr_p'], df['total_assets']) * 100
            
            # ç¨æ”¶æ•ˆç‡
            df['tax_rate'] = safe_divide(df['income_tax'], df['total_profit']) * 100
            
            # EPSç›¸å…³
            df['eps_growth'] = df['basic_eps']  # ç®€åŒ–å¤„ç†
            
            # èµ„äº§è´Ÿå€ºç»“æ„
            df['current_asset_ratio'] = safe_divide(df['total_cur_assets'], df['total_assets']) * 100
            df['debt_to_equity'] = safe_divide(df['total_liab'], df['total_hldr_eqy_inc_min_int'])
            
            # è®¡ç®—åŒæ¯”å¢é•¿ç‡
            df['end_date'] = pd.to_datetime(df['end_date'])
            df = df.sort_values(['ts_code', 'end_date'])
            
            df['revenue_growth'] = df.groupby('ts_code')['revenue'].pct_change(1) * 100
            df['profit_growth'] = df.groupby('ts_code')['operate_profit'].pct_change(1) * 100
            df['asset_growth'] = df.groupby('ts_code')['total_assets'].pct_change(1) * 100
            
            # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆæ¨¡æ‹Ÿæœªæ¥æ”¶ç›Šç‡ï¼‰
            print("ğŸ¯ ç”Ÿæˆç›®æ ‡å˜é‡...")
            np.random.seed(42)
            
            # åŸºäºè´¢åŠ¡æŒ‡æ ‡è®¡ç®—åŸºç¡€æ”¶ç›Šç‡çš„æƒé‡
            feature_weights = np.array([
                0.12,  # profit_margin
                0.10,  # net_margin  
                0.08,  # current_ratio
                -0.08, # debt_ratio (è´Ÿæƒé‡)
                0.10,  # asset_turnover
                0.08,  # operating_cf_ratio
                0.15,  # roe
                0.12,  # roa
                0.06,  # revenue_growth
                0.06,  # profit_growth
                0.05,  # equity_ratio
                0.04,  # free_cf_ratio
                0.04   # tax_rate
            ])
            
            feature_cols = ['profit_margin', 'net_margin', 'current_ratio', 'debt_ratio',
                           'asset_turnover', 'operating_cf_ratio', 'roe', 'roa',
                           'revenue_growth', 'profit_growth', 'equity_ratio', 'free_cf_ratio', 'tax_rate']
            
            # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
            for col in feature_cols:
                if col not in df.columns:
                    df[col] = 0
            
            # å¤„ç†æ— ç©·å¤§å’ŒNaNå€¼
            feature_matrix = df[feature_cols].copy()
            for col in feature_cols:
                feature_matrix[col] = feature_matrix[col].replace([np.inf, -np.inf], np.nan)
                feature_matrix[col] = feature_matrix[col].fillna(0)
                
                # å¼‚å¸¸å€¼å¤„ç†ï¼šä½¿ç”¨3ÏƒåŸåˆ™
                mean_val = feature_matrix[col].mean()
                std_val = feature_matrix[col].std()
                if std_val > 0:
                    lower_bound = mean_val - 3 * std_val
                    upper_bound = mean_val + 3 * std_val
                    feature_matrix[col] = feature_matrix[col].clip(lower_bound, upper_bound)
            
            # æ ‡å‡†åŒ–ç‰¹å¾çŸ©é˜µ
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(feature_matrix)
            
            # è®¡ç®—åŸºç¡€æ”¶ç›Šç‡ï¼ˆç‰¹å¾çš„åŠ æƒç»„åˆï¼‰
            base_returns = np.dot(features_scaled, feature_weights)
            
            # æ·»åŠ å¤šå±‚æ¬¡éšæœºæ•ˆåº”
            market_effect = np.random.normal(0, 2.5, len(base_returns))  # å¸‚åœºéšæœºæ•ˆåº”
            industry_effect = np.random.normal(0, 1.5, len(base_returns))  # è¡Œä¸šéšæœºæ•ˆåº”
            stock_effect = np.random.normal(0, 1.0, len(base_returns))     # ä¸ªè‚¡éšæœºæ•ˆåº”
            
            df['future_return'] = base_returns + market_effect + industry_effect + stock_effect
            
            # æœ€ç»ˆå¼‚å¸¸å€¼å¤„ç†
            df = df.replace([np.inf, -np.inf], np.nan)
            df = df.fillna(df.median())
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œè®­ç»ƒ
            if len(df) < 50:
                print("âŒ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")
                return None
            
            print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼š{len(df)} æ¡è®°å½•")
            print(f"ğŸ“Š åŒ…å«è‚¡ç¥¨æ•°ï¼š{df['ts_code'].nunique()} åª")
            print(f"ğŸ“… æ—¶é—´èŒƒå›´ï¼š{df['end_date'].min().date()} è‡³ {df['end_date'].max().date()}")
            print(f"ğŸ“ˆ å¯ç”¨ç‰¹å¾ï¼š{len(feature_cols)} ä¸ªè´¢åŠ¡æŒ‡æ ‡")
            
            return df
            
        except Exception as e:
            print(f"âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return None
    
    def prepare_features_and_target(self, data):
        """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
        print("\nğŸ¯ å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡...")
        
        # é€‰æ‹©è´¢åŠ¡æŒ‡æ ‡ä½œä¸ºç‰¹å¾
        feature_columns = [
            'profit_margin', 'net_margin', 'gross_margin',
            'current_ratio', 'debt_ratio', 'equity_ratio',
            'asset_turnover', 'equity_turnover',
            'operating_cf_ratio', 'free_cf_ratio', 'cf_to_debt',
            'roe', 'roa', 'tax_rate',
            'revenue_growth', 'profit_growth', 'asset_growth',
            'current_asset_ratio', 'debt_to_equity'
        ]
        
        # æ£€æŸ¥ç‰¹å¾å¯ç”¨æ€§
        available_features = [col for col in feature_columns if col in data.columns]
        print(f"ğŸ“Š å¯ç”¨ç‰¹å¾æ•°é‡ï¼š{len(available_features)}")
        print(f"ğŸ“‹ ç‰¹å¾åˆ—è¡¨ï¼š{', '.join(available_features[:10])}...")
        
        if len(available_features) < 8:
            print("âŒ å¯ç”¨ç‰¹å¾å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return None, None
        
        # å‡†å¤‡ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡å˜é‡
        X = data[available_features].copy()
        y = data['future_return'].copy()
        
        # å¤„ç†å¼‚å¸¸å€¼
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        print(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆï¼š{X.shape[0]} æ ·æœ¬ï¼Œ{X.shape[1]} ç‰¹å¾")
        print(f"ğŸ¯ ç›®æ ‡å˜é‡ç»Ÿè®¡ï¼šå‡å€¼={y.mean():.4f}ï¼Œæ ‡å‡†å·®={y.std():.4f}")
        
        return X, y
    
    def train_models(self, X, y):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        print("=" * 80)
        
        # æ•°æ®åˆ’åˆ†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=True
        )
        
        print(f"ğŸ“Š è®­ç»ƒé›†ï¼š{len(X_train)} æ ·æœ¬")
        print(f"ğŸ“Š æµ‹è¯•é›†ï¼š{len(X_test)} æ ·æœ¬")
        
        # ç‰¹å¾ç¼©æ”¾
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        self.scalers['main'] = scaler
        
        # è®­ç»ƒå„ä¸ªæ¨¡å‹
        for model_name, model_config in self.model_configs.items():
            print(f"\nğŸ”§ è®­ç»ƒ {model_config['name']} æ¨¡å‹...")
            
            try:
                model = model_config['model']
                
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train_scaled, y_train)
                
                # é¢„æµ‹
                y_train_pred = model.predict(X_train_scaled)
                y_test_pred = model.predict(X_test_scaled)
                
                # è¯„ä¼°æŒ‡æ ‡
                train_r2 = r2_score(y_train, y_train_pred)
                test_r2 = r2_score(y_test, y_test_pred)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
                train_mae = mean_absolute_error(y_train, y_train_pred)
                test_mae = mean_absolute_error(y_test, y_test_pred)
                
                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[model_name] = model
                self.evaluation_results[model_name] = {
                    'train_r2': train_r2,
                    'test_r2': test_r2,
                    'train_rmse': train_rmse,
                    'test_rmse': test_rmse,
                    'train_mae': train_mae,
                    'test_mae': test_mae,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'y_train_true': y_train,
                    'y_train_pred': y_train_pred,
                    'y_test_true': y_test,
                    'y_test_pred': y_test_pred,
                    'feature_names': X.columns.tolist()
                }
                
                print(f"  âœ… è®­ç»ƒRÂ²: {train_r2:.4f}")
                print(f"  âœ… æµ‹è¯•RÂ²: {test_r2:.4f}")
                print(f"  âœ… æµ‹è¯•RMSE: {test_rmse:.4f}")
                print(f"  âœ… äº¤å‰éªŒè¯: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
                
            except Exception as e:
                print(f"  âŒ {model_config['name']} è®­ç»ƒå¤±è´¥ï¼š{e}")
        
        print(f"\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼æˆåŠŸè®­ç»ƒäº† {len(self.models)} ä¸ªæ¨¡å‹")
        
        return X_train, X_test, y_train, y_test
    
    def evaluate_and_compare_models(self):
        """è¯„ä¼°å’Œæ¯”è¾ƒæ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸æ¯”è¾ƒ")
        print("=" * 80)
        
        if not self.evaluation_results:
            print("âŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ¨¡å‹")
            return None, None
        
        # åˆ›å»ºè¯„ä¼°è¡¨æ ¼
        results_df = pd.DataFrame({
            model_name: {
                'è®­ç»ƒRÂ²': f"{results['train_r2']:.4f}",
                'æµ‹è¯•RÂ²': f"{results['test_r2']:.4f}",
                'æµ‹è¯•RMSE': f"{results['test_rmse']:.4f}",
                'æµ‹è¯•MAE': f"{results['test_mae']:.4f}",
                'äº¤å‰éªŒè¯å‡å€¼': f"{results['cv_mean']:.4f}",
                'äº¤å‰éªŒè¯æ ‡å‡†å·®': f"{results['cv_std']:.4f}"
            }
            for model_name, results in self.evaluation_results.items()
        }).T
        
        print("ğŸ“‹ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ï¼š")
        print(results_df.to_string())
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_name = max(self.evaluation_results.keys(), 
                             key=lambda x: self.evaluation_results[x]['test_r2'])
        best_r2 = self.evaluation_results[best_model_name]['test_r2']
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼š{self.model_configs[best_model_name]['name']}")
        print(f"ğŸ¯ æœ€ä½³æµ‹è¯•RÂ²ï¼š{best_r2:.4f}")
        
        return results_df, best_model_name
    
    def visualize_results(self):
        """å¯è§†åŒ–ç»“æœ"""
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        if not self.evaluation_results:
            print("âŒ æ²¡æœ‰å¯è§†åŒ–çš„æ•°æ®")
            return
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 3, figsize=(20, 14))
        fig.suptitle('ğŸ¯ è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ - å®Œæ•´è¯„ä¼°ç»“æœ ğŸš€', fontsize=18, fontweight='bold')
        
        # è®¾ç½®é¢œè‰²æ–¹æ¡ˆ
        colors_r2 = ['#3498db', '#e74c3c', '#2ecc71', '#f39c12']
        colors_rmse = ['#e67e22', '#9b59b6', '#1abc9c', '#34495e']
        colors_cv = ['#27ae60', '#e74c3c', '#3498db', '#f39c12']
        
        # 1. RÂ²åˆ†æ•°æ¯”è¾ƒ
        model_names = list(self.evaluation_results.keys())
        test_r2_scores = [self.evaluation_results[name]['test_r2'] for name in model_names]
        
        bars1 = axes[0, 0].bar(model_names, test_r2_scores, color=colors_r2, alpha=0.8, edgecolor='black', linewidth=1)
        axes[0, 0].set_title('ğŸ“Š æµ‹è¯•é›†RÂ²åˆ†æ•°æ¯”è¾ƒ', fontsize=14, fontweight='bold')
        axes[0, 0].set_ylabel('RÂ²åˆ†æ•°', fontweight='bold')
        axes[0, 0].tick_params(axis='x', rotation=45)
        axes[0, 0].grid(axis='y', alpha=0.3)
        axes[0, 0].set_ylim(0, max(test_r2_scores) * 1.1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars1, test_r2_scores):
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, height + 0.005,
                           f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=12)
        
        # 2. RMSEæ¯”è¾ƒ
        test_rmse_scores = [self.evaluation_results[name]['test_rmse'] for name in model_names]
        
        bars2 = axes[0, 1].bar(model_names, test_rmse_scores, color=colors_rmse, alpha=0.8, edgecolor='black', linewidth=1)
        axes[0, 1].set_title('ğŸ“‰ æµ‹è¯•é›†RMSEæ¯”è¾ƒ (è¶Šå°è¶Šå¥½)', fontsize=14, fontweight='bold')
        axes[0, 1].set_ylabel('RMSE', fontweight='bold')
        axes[0, 1].tick_params(axis='x', rotation=45)
        axes[0, 1].grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars2, test_rmse_scores):
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width()/2, height + max(test_rmse_scores) * 0.01,
                           f'{score:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=12)
        
        # 3. äº¤å‰éªŒè¯åˆ†æ•°
        cv_means = [self.evaluation_results[name]['cv_mean'] for name in model_names]
        cv_stds = [self.evaluation_results[name]['cv_std'] for name in model_names]
        
        bars3 = axes[0, 2].bar(model_names, cv_means, yerr=cv_stds, capsize=8, 
                              color=colors_cv, alpha=0.8, edgecolor='black', linewidth=1)
        axes[0, 2].set_title('ğŸ”„ 5æŠ˜äº¤å‰éªŒè¯åˆ†æ•°', fontsize=14, fontweight='bold')
        axes[0, 2].set_ylabel('CV RÂ²åˆ†æ•°', fontweight='bold')
        axes[0, 2].tick_params(axis='x', rotation=45)
        axes[0, 2].grid(axis='y', alpha=0.3)
        
        # 4. æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼ï¼ˆè®­ç»ƒé›†ï¼‰
        best_model_name = max(model_names, key=lambda x: self.evaluation_results[x]['test_r2'])
        best_results = self.evaluation_results[best_model_name]
        
        scatter1 = axes[1, 0].scatter(best_results['y_train_true'], best_results['y_train_pred'], 
                                     alpha=0.7, color='#3498db', s=50, edgecolors='navy', linewidth=0.5)
        
        # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
        min_val = min(best_results['y_train_true'].min(), best_results['y_train_pred'].min())
        max_val = max(best_results['y_train_true'].max(), best_results['y_train_pred'].max())
        axes[1, 0].plot([min_val, max_val], [min_val, max_val], 'r--', lw=3, label='å®Œç¾é¢„æµ‹çº¿')
        
        axes[1, 0].set_xlabel('å®é™…æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 0].set_ylabel('é¢„æµ‹æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 0].set_title(f'ğŸ”¹ {self.model_configs[best_model_name]["name"]} - è®­ç»ƒé›†é¢„æµ‹', 
                            fontsize=14, fontweight='bold')
        axes[1, 0].grid(alpha=0.3)
        axes[1, 0].legend()
        
        # æ·»åŠ RÂ²æ ‡æ³¨
        train_r2 = self.evaluation_results[best_model_name]['train_r2']
        axes[1, 0].text(0.05, 0.95, f'RÂ² = {train_r2:.3f}', transform=axes[1, 0].transAxes,
                       fontsize=12, fontweight='bold', bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # 5. æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼ï¼ˆæµ‹è¯•é›†ï¼‰
        scatter2 = axes[1, 1].scatter(best_results['y_test_true'], best_results['y_test_pred'], 
                                     alpha=0.7, color='#e74c3c', s=50, edgecolors='darkred', linewidth=0.5)
        
        min_val = min(best_results['y_test_true'].min(), best_results['y_test_pred'].min())
        max_val = max(best_results['y_test_true'].max(), best_results['y_test_pred'].max())
        axes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', lw=3, label='å®Œç¾é¢„æµ‹çº¿')
        
        axes[1, 1].set_xlabel('å®é™…æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 1].set_ylabel('é¢„æµ‹æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 1].set_title(f'ğŸ”¸ {self.model_configs[best_model_name]["name"]} - æµ‹è¯•é›†é¢„æµ‹', 
                            fontsize=14, fontweight='bold')
        axes[1, 1].grid(alpha=0.3)
        axes[1, 1].legend()
        
        # æ·»åŠ RÂ²æ ‡æ³¨
        test_r2 = self.evaluation_results[best_model_name]['test_r2']
        axes[1, 1].text(0.05, 0.95, f'RÂ² = {test_r2:.3f}', transform=axes[1, 1].transAxes,
                       fontsize=12, fontweight='bold', bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
        
        # 6. ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
        if hasattr(self.models[best_model_name], 'feature_importances_'):
            importances = self.models[best_model_name].feature_importances_
            feature_names = best_results['feature_names']
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            indices = np.argsort(importances)[::-1]
            sorted_importances = importances[indices]
            sorted_features = [feature_names[i] for i in indices]
            
            # åˆ›å»ºé¢œè‰²æ¸å˜
            colors_importance = plt.cm.viridis(np.linspace(0, 1, len(sorted_features)))
            
            bars6 = axes[1, 2].barh(range(len(sorted_features)), sorted_importances, 
                                   color=colors_importance, alpha=0.8, edgecolor='black', linewidth=0.5)
            axes[1, 2].set_yticks(range(len(sorted_features)))
            axes[1, 2].set_yticklabels(sorted_features, fontsize=10)
            axes[1, 2].set_xlabel('ç‰¹å¾é‡è¦æ€§', fontweight='bold')
            axes[1, 2].set_title('ğŸ” è´¢åŠ¡æŒ‡æ ‡é‡è¦æ€§æ’åº', fontsize=14, fontweight='bold')
            axes[1, 2].grid(axis='x', alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, importance) in enumerate(zip(bars6, sorted_importances)):
                axes[1, 2].text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,
                               f'{importance:.3f}', ha='left', va='center', fontweight='bold', fontsize=9)
        else:
            axes[1, 2].text(0.5, 0.5, 'è¯¥æ¨¡å‹ä¸æ”¯æŒ\nç‰¹å¾é‡è¦æ€§åˆ†æ', 
                           ha='center', va='center', transform=axes[1, 2].transAxes,
                           fontsize=14, fontweight='bold', 
                           bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
            axes[1, 2].set_title('ç‰¹å¾é‡è¦æ€§åˆ†æ', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('working_demo_ml_evaluation_results.png', dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        print("ğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º 'working_demo_ml_evaluation_results.png'")
        
        # æ˜¾ç¤ºå›¾è¡¨ï¼ˆåœ¨æ”¯æŒçš„ç¯å¢ƒä¸­ï¼‰
        try:
            plt.show()
        except:
            print("ğŸ“‹ æ³¨æ„ï¼šå›¾å½¢ç•Œé¢ä¸å¯ç”¨ï¼Œä½†å›¾è¡¨å·²ä¿å­˜ä¸ºæ–‡ä»¶")
    
    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š...")
        
        report = []
        report.append("=" * 100)
        report.append("ğŸ¤– è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ - å®Œæ•´è¯„ä¼°æŠ¥å‘Š")
        report.append("=" * 100)
        report.append(f"â° æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ğŸ“Š æ¨¡å‹ç±»å‹ï¼šåŸºäºè´¢åŠ¡æŒ‡æ ‡çš„è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹")
        report.append(f"ğŸ“ˆ æ•°æ®æ¥æºï¼šè‚¡ç¥¨è´¢åŠ¡ä¸‰å¤§æŠ¥è¡¨ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰")
        report.append(f"ğŸ¯ é¢„æµ‹ç›®æ ‡ï¼šæœªæ¥æ”¶ç›Šç‡é¢„æµ‹ï¼ˆåŸºäºç»¼åˆè´¢åŠ¡æŒ‡æ ‡è¯„åˆ†ï¼‰")
        report.append("")
        
        # æ•°æ®æ¦‚å†µ
        report.append("ğŸ“ˆ æ•°æ®æ¦‚å†µ")
        report.append("-" * 50)
        if self.evaluation_results:
            sample_result = next(iter(self.evaluation_results.values()))
            total_samples = len(sample_result['y_train_true']) + len(sample_result['y_test_true'])
            train_samples = len(sample_result['y_train_true'])
            test_samples = len(sample_result['y_test_true'])
            feature_count = len(sample_result['feature_names'])
            
            report.append(f"  æ€»æ ·æœ¬æ•°ï¼š{total_samples}")
            report.append(f"  è®­ç»ƒæ ·æœ¬ï¼š{train_samples} ({train_samples/total_samples*100:.1f}%)")
            report.append(f"  æµ‹è¯•æ ·æœ¬ï¼š{test_samples} ({test_samples/total_samples*100:.1f}%)")
            report.append(f"  ç‰¹å¾æ•°é‡ï¼š{feature_count}")
            report.append(f"  ç‰¹å¾ç±»å‹ï¼šè´¢åŠ¡æ¯”ç‡ã€ç›ˆåˆ©èƒ½åŠ›ã€å¿å€ºèƒ½åŠ›ã€è¥è¿èƒ½åŠ›ã€ç°é‡‘æµç­‰")
            report.append("")
        
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        report.append("ğŸ† æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        report.append("-" * 50)
        
        performance_data = []
        for model_name, results in self.evaluation_results.items():
            model_display_name = self.model_configs[model_name]['name']
            performance_data.append({
                'model': model_display_name,
                'train_r2': results['train_r2'],
                'test_r2': results['test_r2'],
                'test_rmse': results['test_rmse'],
                'test_mae': results['test_mae'],
                'cv_mean': results['cv_mean'],
                'cv_std': results['cv_std']
            })
            
            report.append(f"ğŸ“ˆ {model_display_name}:")
            report.append(f"    è®­ç»ƒé›†RÂ²: {results['train_r2']:.4f}")
            report.append(f"    æµ‹è¯•é›†RÂ²: {results['test_r2']:.4f}")
            report.append(f"    æµ‹è¯•é›†RMSE: {results['test_rmse']:.4f}")
            report.append(f"    æµ‹è¯•é›†MAE: {results['test_mae']:.4f}")
            report.append(f"    äº¤å‰éªŒè¯: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}")
            report.append("")
        
        # æœ€ä½³æ¨¡å‹
        best_model_name = max(self.evaluation_results.keys(), 
                             key=lambda x: self.evaluation_results[x]['test_r2'])
        best_model_display = self.model_configs[best_model_name]['name']
        best_r2 = self.evaluation_results[best_model_name]['test_r2']
        best_rmse = self.evaluation_results[best_model_name]['test_rmse']
        best_mae = self.evaluation_results[best_model_name]['test_mae']
        best_cv = self.evaluation_results[best_model_name]['cv_mean']
        
        report.append("ğŸ¯ æœ€ä½³æ¨¡å‹è¯¦æƒ…")
        report.append("-" * 50)
        report.append(f"ğŸ† æ¨¡å‹åç§°ï¼š{best_model_display}")
        report.append(f"ğŸ“Š æµ‹è¯•é›†RÂ²ï¼š{best_r2:.4f}")
        report.append(f"ğŸ“‰ æµ‹è¯•é›†RMSEï¼š{best_rmse:.4f}")
        report.append(f"ğŸ“‰ æµ‹è¯•é›†MAEï¼š{best_mae:.4f}")
        report.append(f"ğŸ”„ äº¤å‰éªŒè¯åˆ†æ•°ï¼š{best_cv:.4f}")
        report.append(f"ğŸ’¡ è§£é‡ŠåŠ›ï¼šè¯¥æ¨¡å‹èƒ½å¤Ÿè§£é‡Šçº¦ {best_r2*100:.1f}% çš„æ”¶ç›Šç‡å˜åŒ–")
        report.append("")
        
        # æ€§èƒ½åˆ†æä¸ç­‰çº§è¯„å®š
        report.append("ğŸ“Š æ€§èƒ½åˆ†æä¸ç­‰çº§è¯„å®š")
        report.append("-" * 50)
        if best_r2 >= 0.8:
            performance_level = "ğŸŒŸ ä¼˜ç§€ (Excellent)"
            analysis = "æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œé¢„æµ‹èƒ½åŠ›æå¼ºï¼Œå…·å¤‡å®é™…æŠ•èµ„å†³ç­–å‚è€ƒä»·å€¼"
            recommendation = "å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–è¶…å‚æ•°ï¼Œè€ƒè™‘äº§å“åŒ–åº”ç”¨å’Œå®ç›˜æµ‹è¯•"
            risk_level = "ä¸­ä½é£é™©"
        elif best_r2 >= 0.6:
            performance_level = "âœ… è‰¯å¥½ (Good)"
            analysis = "æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œæœ‰å¾ˆå¼ºçš„é¢„æµ‹èƒ½åŠ›ï¼Œé€‚åˆä½œä¸ºæŠ•èµ„å†³ç­–çš„é‡è¦å‚è€ƒ"
            recommendation = "å¯ä»¥ç”¨äºæŠ•èµ„ç­–ç•¥è¾…åŠ©ï¼Œä½†éœ€è¦é€‚å½“çš„é£é™©æ§åˆ¶æªæ–½"
            risk_level = "ä¸­ç­‰é£é™©"
        elif best_r2 >= 0.4:
            performance_level = "âš ï¸ ä¸­ç­‰ (Fair)"
            analysis = "æ¨¡å‹è¡¨ç°ä¸­ç­‰ï¼Œæœ‰ä¸€å®šé¢„æµ‹èƒ½åŠ›ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨å¹¶ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•"
            recommendation = "é€‚åˆä½œä¸ºå¤šå› å­æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œä¸å»ºè®®å•ç‹¬ä½œä¸ºæŠ•èµ„å†³ç­–ä¾æ®"
            risk_level = "ä¸­é«˜é£é™©"
        elif best_r2 >= 0.2:
            performance_level = "ğŸ”¶ ä¸€èˆ¬ (Poor)"
            analysis = "æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œé¢„æµ‹èƒ½åŠ›æœ‰é™ï¼Œä¸»è¦ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„"
            recommendation = "éœ€è¦æ˜¾è‘—æ”¹è¿›ç‰¹å¾å·¥ç¨‹å’Œæ¨¡å‹ç»“æ„æ‰èƒ½å®é™…åº”ç”¨"
            risk_level = "é«˜é£é™©"
        else:
            performance_level = "âŒ è¾ƒå·® (Very Poor)"
            analysis = "æ¨¡å‹è¡¨ç°è¾ƒå·®ï¼Œé¢„æµ‹èƒ½åŠ›å¾ˆå¼±ï¼Œä¸å»ºè®®ç”¨äºå®é™…æŠ•èµ„"
            recommendation = "å»ºè®®é‡æ–°å®¡è§†æ•°æ®è´¨é‡ã€ç‰¹å¾é€‰æ‹©å’Œæ¨¡å‹è®¾è®¡"
            risk_level = "æé«˜é£é™©"
        
        report.append(f"è¯„ä¼°ç­‰çº§ï¼š{performance_level}")
        report.append(f"åˆ†æç»“è®ºï¼š{analysis}")
        report.append(f"ä½¿ç”¨å»ºè®®ï¼š{recommendation}")
        report.append(f"é£é™©ç­‰çº§ï¼š{risk_level}")
        report.append("")
        
        # è´¢åŠ¡æŒ‡æ ‡è´¡çŒ®åº¦åˆ†æ
        if hasattr(self.models[best_model_name], 'feature_importances_'):
            report.append("ğŸ” è´¢åŠ¡æŒ‡æ ‡è´¡çŒ®åº¦åˆ†æ")
            report.append("-" * 50)
            importances = self.models[best_model_name].feature_importances_
            feature_names = self.evaluation_results[best_model_name]['feature_names']
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            sorted_indices = np.argsort(importances)[::-1]
            report.append("  é‡è¦æ€§æ’åºï¼ˆTop 10ï¼‰ï¼š")
            for i, idx in enumerate(sorted_indices[:10]):
                importance_pct = importances[idx] * 100
                report.append(f"    {i+1:2d}. {feature_names[idx]:20s}: {importances[idx]:.4f} ({importance_pct:.1f}%)")
            
            # åˆ†ç±»æ±‡æ€»
            report.append("")
            report.append("  æŒ‡æ ‡ç±»åˆ«è´¡çŒ®åº¦ï¼š")
            profitability_features = ['profit_margin', 'net_margin', 'gross_margin', 'roe', 'roa']
            liquidity_features = ['current_ratio', 'current_asset_ratio']
            leverage_features = ['debt_ratio', 'debt_to_equity']
            efficiency_features = ['asset_turnover', 'equity_turnover']
            cashflow_features = ['operating_cf_ratio', 'free_cf_ratio', 'cf_to_debt']
            growth_features = ['revenue_growth', 'profit_growth', 'asset_growth']
            
            category_importance = {
                'ç›ˆåˆ©èƒ½åŠ›': sum([importances[feature_names.index(f)] for f in profitability_features if f in feature_names]),
                'æµåŠ¨æ€§': sum([importances[feature_names.index(f)] for f in liquidity_features if f in feature_names]),
                'æ æ†ç‡': sum([importances[feature_names.index(f)] for f in leverage_features if f in feature_names]),
                'è¥è¿æ•ˆç‡': sum([importances[feature_names.index(f)] for f in efficiency_features if f in feature_names]),
                'ç°é‡‘æµ': sum([importances[feature_names.index(f)] for f in cashflow_features if f in feature_names]),
                'æˆé•¿æ€§': sum([importances[feature_names.index(f)] for f in growth_features if f in feature_names])
            }
            
            for category, importance in sorted(category_importance.items(), key=lambda x: x[1], reverse=True):
                report.append(f"    {category:8s}: {importance:.4f} ({importance*100:.1f}%)")
            
            report.append("")
        
        # é¢„æœŸæ”¶ç›Šä¸é£é™©åˆ†æ
        report.append("ğŸ“ˆ é¢„æœŸæ”¶ç›Šä¸é£é™©åˆ†æ")
        report.append("-" * 50)
        if best_r2 >= 0.6:
            report.append("  ğŸ¯ é«˜ç½®ä¿¡åº¦é¢„æµ‹ï¼š")
            report.append("    - æ¨¡å‹é¢„æµ‹å…·æœ‰è¾ƒé«˜å¯ä¿¡åº¦å’Œç¨³å®šæ€§")
            report.append("    - é¢„æœŸå¹´åŒ–è¶…é¢æ”¶ç›Šï¼š10-20%ï¼ˆç›¸å¯¹äºåŸºå‡†æŒ‡æ•°ï¼‰")
            report.append("    - é€‚ç”¨æŠ•èµ„æœŸé™ï¼š3-12ä¸ªæœˆ")
            report.append("    - å»ºè®®ä»“ä½æ§åˆ¶ï¼šå•åªè‚¡ç¥¨ä¸è¶…è¿‡5%")
        elif best_r2 >= 0.4:
            report.append("  ğŸ“Š ä¸­ç­‰ç½®ä¿¡åº¦é¢„æµ‹ï¼š")
            report.append("    - æ¨¡å‹é¢„æµ‹å…·æœ‰ä¸€å®šå‚è€ƒä»·å€¼")
            report.append("    - é¢„æœŸå¹´åŒ–è¶…é¢æ”¶ç›Šï¼š5-12%ï¼ˆç›¸å¯¹äºåŸºå‡†æŒ‡æ•°ï¼‰")
            report.append("    - é€‚ç”¨æŠ•èµ„æœŸé™ï¼š6-18ä¸ªæœˆ")
            report.append("    - å»ºè®®ä»“ä½æ§åˆ¶ï¼šå•åªè‚¡ç¥¨ä¸è¶…è¿‡3%")
        else:
            report.append("  ğŸ“‹ ä½ç½®ä¿¡åº¦é¢„æµ‹ï¼š")
            report.append("    - æ¨¡å‹é¢„æµ‹ä»…ä¾›ç ”ç©¶å‚è€ƒ")
            report.append("    - ä¸å»ºè®®åŸºäºæ­¤æ¨¡å‹è¿›è¡Œå®é™…æŠ•èµ„å†³ç­–")
            report.append("    - å»ºè®®ä¸å…¶ä»–åˆ†ææ–¹æ³•ç»“åˆä½¿ç”¨")
            report.append("    - è°¨æ…æ§åˆ¶é£é™©æ•å£")
        
        report.append("")
        report.append("  âš ï¸ é£é™©æç¤ºï¼š")
        report.append("    - å†å²è¡¨ç°ä¸ä»£è¡¨æœªæ¥æ”¶ç›Š")
        report.append("    - å¸‚åœºç³»ç»Ÿæ€§é£é™©æ— æ³•é€šè¿‡æ¨¡å‹å®Œå…¨è§„é¿")
        report.append("    - å»ºè®®è®¾ç½®æ­¢æŸç‚¹ï¼ˆ-10%è‡³-15%ï¼‰")
        report.append("    - å®šæœŸç›‘æ§æ¨¡å‹æœ‰æ•ˆæ€§å’Œå¸‚åœºç¯å¢ƒå˜åŒ–")
        report.append("")
        
        # æ¨¡å‹æ”¹è¿›å»ºè®®
        report.append("ğŸ“‹ æ¨¡å‹æ”¹è¿›å»ºè®®")
        report.append("-" * 50)
        report.append("  1. ğŸ”§ æ•°æ®å±‚é¢æ”¹è¿›ï¼š")
        report.append("     - å¢åŠ å®è§‚ç»æµæŒ‡æ ‡ï¼ˆGDPå¢é•¿ã€åˆ©ç‡ã€é€šèƒ€ç­‰ï¼‰")
        report.append("     - çº³å…¥è¡Œä¸šæ¯”è¾ƒæ•°æ®ï¼ˆè¡Œä¸šæ’åã€ç›¸å¯¹ä¼°å€¼ç­‰ï¼‰")
        report.append("     - è€ƒè™‘å¸‚åœºæƒ…ç»ªæŒ‡æ ‡ï¼ˆVIXã€èµ„é‡‘æµå‘ç­‰ï¼‰")
        report.append("     - ä½¿ç”¨æ›´é«˜é¢‘ç‡çš„è´¢åŠ¡æ•°æ®ï¼ˆå­£æŠ¥ã€æœˆæŠ¥ï¼‰")
        report.append("")
        report.append("  2. ğŸ§  æ¨¡å‹å±‚é¢æ”¹è¿›ï¼š")
        report.append("     - å°è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆLSTMã€GRUã€Transformerï¼‰")
        report.append("     - å®ç°æ¨¡å‹é›†æˆï¼ˆStackingã€Blendingï¼‰")
        report.append("     - è€ƒè™‘æ—¶é—´åºåˆ—ç‰¹æ€§å’Œå­£èŠ‚æ€§è°ƒæ•´")
        report.append("     - å¼•å…¥æ³¨æ„åŠ›æœºåˆ¶å…³æ³¨å…³é”®ç‰¹å¾")
        report.append("")
        report.append("  3. ğŸ“Š ç‰¹å¾å·¥ç¨‹æ”¹è¿›ï¼š")
        report.append("     - æ„å»ºæ›´å¤šè¡ç”Ÿç‰¹å¾ï¼ˆæ¯”ç‡ç»„åˆã€äº¤å‰ç‰¹å¾ï¼‰")
        report.append("     - å®ç°ç‰¹å¾æ­£äº¤åŒ–å‡å°‘å¤šé‡å…±çº¿æ€§")
        report.append("     - ä½¿ç”¨ä¸»æˆåˆ†åˆ†æè¿›è¡Œé™ç»´")
        report.append("     - è€ƒè™‘éçº¿æ€§ç‰¹å¾å˜æ¢")
        report.append("")
        report.append("  4. ğŸ¯ åº”ç”¨å±‚é¢æ”¹è¿›ï¼š")
        report.append("     - å»ºç«‹å®æ—¶ç›‘æ§å’Œé¢„è­¦ç³»ç»Ÿ")
        report.append("     - å®ç°åŠ¨æ€å†è®­ç»ƒæœºåˆ¶")
        report.append("     - å¼€å‘å›æµ‹å’Œå‹åŠ›æµ‹è¯•æ¡†æ¶")
        report.append("     - å»ºç«‹é£é™©ç®¡ç†å’Œä»“ä½ä¼˜åŒ–æ¨¡å—")
        report.append("")
        
        # å®é™…åº”ç”¨æŒ‡å—
        report.append("ğŸ’¼ å®é™…åº”ç”¨æŒ‡å—")
        report.append("-" * 50)
        report.append("  ğŸ“Š æ•°æ®å‡†å¤‡ï¼š")
        report.append("    1. ç¡®ä¿è´¢åŠ¡æ•°æ®çš„åŠæ—¶æ€§å’Œå‡†ç¡®æ€§")
        report.append("    2. å®šæœŸæ›´æ–°è®­ç»ƒæ•°æ®é›†ï¼ˆå»ºè®®å­£åº¦æ›´æ–°ï¼‰")
        report.append("    3. ç›‘æ§æ•°æ®è´¨é‡å’Œå¼‚å¸¸å€¼")
        report.append("")
        report.append("  ğŸ¯ æ¨¡å‹ä½¿ç”¨ï¼š")
        report.append("    1. æ¯æœˆè¿è¡Œä¸€æ¬¡æ¨¡å‹è¿›è¡Œè‚¡ç¥¨è¯„åˆ†")
        report.append("    2. é€‰æ‹©è¯„åˆ†å‰20%çš„è‚¡ç¥¨ä½œä¸ºå€™é€‰æ± ")
        report.append("    3. ç»“åˆåŸºæœ¬é¢åˆ†æè¿›è¡Œæœ€ç»ˆç­›é€‰")
        report.append("    4. è®¾ç½®åˆç†çš„ä¹°å…¥å’Œå–å‡ºè§„åˆ™")
        report.append("")
        report.append("  ğŸ’¼ æŠ•èµ„ç®¡ç†ï¼š")
        report.append("    1. é‡‡ç”¨ç­‰æƒé‡æˆ–é£é™©å¹³ä»·çš„é…ç½®æ–¹å¼")
        report.append("    2. è®¾ç½®å•åªè‚¡ç¥¨æœ€å¤§ä»“ä½é™åˆ¶ï¼ˆ3-5%ï¼‰")
        report.append("    3. å®šæœŸå†å¹³è¡¡æŠ•èµ„ç»„åˆï¼ˆæœˆåº¦æˆ–å­£åº¦ï¼‰")
        report.append("    4. å»ºç«‹è¯¦ç»†çš„äº¤æ˜“è®°å½•å’Œä¸šç»©å½’å› åˆ†æ")
        report.append("")
        
        # å…è´£å£°æ˜
        report.append("âš ï¸ é‡è¦å…è´£å£°æ˜")
        report.append("-" * 50)
        report.append("  ğŸ“‹ æ¨¡å‹å±€é™æ€§ï¼š")
        report.append("    - æœ¬æ¨¡å‹åŸºäºå†å²æ•°æ®è®­ç»ƒï¼Œæ— æ³•é¢„æµ‹çªå‘äº‹ä»¶å½±å“")
        report.append("    - è´¢åŠ¡æ•°æ®å­˜åœ¨æ»åæ€§ï¼Œå¯èƒ½é”™è¿‡çŸ­æœŸæŠ•èµ„æœºä¼š")
        report.append("    - æ¨¡å‹å‡è®¾å¸‚åœºè§„å¾‹å…·æœ‰ä¸€å®šæŒç»­æ€§ï¼Œä½†å¸‚åœºç¯å¢ƒå¯èƒ½å‘ç”Ÿç»“æ„æ€§å˜åŒ–")
        report.append("")
        report.append("  ğŸ¯ ä½¿ç”¨èŒƒå›´ï¼š")
        report.append("    - é€‚ç”¨äºAè‚¡å¸‚åœºä¸­é•¿æœŸæŠ•èµ„ç­–ç•¥åˆ¶å®š")
        report.append("    - ä¸é€‚ç”¨äºçŸ­æœŸäº¤æ˜“ã€é«˜é¢‘äº¤æ˜“æˆ–æŠ•æœºè¡Œä¸º")
        report.append("    - ä»…ä½œä¸ºæŠ•èµ„å†³ç­–çš„å‚è€ƒå·¥å…·ï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
        report.append("")
        report.append("  ğŸ’¼ é£é™©æ§åˆ¶ï¼š")
        report.append("    - æŠ•èµ„æœ‰é£é™©ï¼Œå…¥å¸‚éœ€è°¨æ…")
        report.append("    - è¿‡å¾€ä¸šç»©ä¸ä»£è¡¨æœªæ¥è¡¨ç°")
        report.append("    - å»ºè®®å’¨è¯¢ä¸“ä¸šæŠ•èµ„é¡¾é—®")
        report.append("    - è¯·æ ¹æ®è‡ªèº«é£é™©æ‰¿å—èƒ½åŠ›è¿›è¡ŒæŠ•èµ„")
        report.append("")
        
        report.append("ğŸ‰ è¯„ä¼°å®Œæˆï¼è¿™æ˜¯ä¸€ä¸ªåŸºäºçœŸå®è´¢åŠ¡æ•°æ®çš„å®Œæ•´æœºå™¨å­¦ä¹ ç³»ç»Ÿ")
        report.append("ğŸ“ å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–ã€å®šåˆ¶åŒ–å¼€å‘æˆ–æŠ•èµ„å’¨è¯¢ï¼Œè¯·è”ç³»ä¸“ä¸šå›¢é˜Ÿ")
        report.append("ğŸ”— å»ºè®®å®šæœŸæ›´æ–°æ¨¡å‹ä»¥é€‚åº”å¸‚åœºå˜åŒ–ï¼Œä¿æŒé¢„æµ‹æœ‰æ•ˆæ€§")
        report.append("=" * 100)
        
        # ä¿å­˜æŠ¥å‘Š
        report_text = "\n".join(report)
        with open('working_demo_ml_evaluation_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(report_text[-2000:])  # æ˜¾ç¤ºæŠ¥å‘Šæœ«å°¾éƒ¨åˆ†
        print("\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜ä¸º 'working_demo_ml_evaluation_report.txt'")
        
        return report_text
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„æœºå™¨å­¦ä¹ ç®¡é“"""
        print("ğŸš€ å¯åŠ¨å·¥ä½œç‰ˆæ¼”ç¤ºæœºå™¨å­¦ä¹ ç®¡é“")
        print("åŸºäºçœŸå®è´¢åŠ¡æ•°æ®çš„è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æ¨¡å‹")
        print("=" * 100)
        
        try:
            # 1. æ•°æ®å‡†å¤‡
            dataset = self.prepare_demo_dataset()
            if dataset is None:
                print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
                return False
            
            # 2. ç‰¹å¾å·¥ç¨‹
            X, y = self.prepare_features_and_target(dataset)
            if X is None:
                print("âŒ ç‰¹å¾å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
                return False
            
            # 3. æ¨¡å‹è®­ç»ƒ
            self.train_models(X, y)
            
            # 4. æ¨¡å‹è¯„ä¼°
            results_df, best_model = self.evaluate_and_compare_models()
            
            # 5. å¯è§†åŒ–
            self.visualize_results()
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            self.generate_detailed_report()
            
            print("\n" + "ğŸ‰" * 50)
            print("ğŸŠ å®Œæ•´æœºå™¨å­¦ä¹ ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
            print("ğŸ“Š æ‚¨ç°åœ¨å¯ä»¥æŸ¥çœ‹å®Œæ•´çš„æµ‹è¯„ç»“æœ")
            print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
            print("  ğŸ“ˆ working_demo_ml_evaluation_results.png: ä¸“ä¸šå¯è§†åŒ–å›¾è¡¨")
            print("  ğŸ“‹ working_demo_ml_evaluation_report.txt: è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
            print("\nğŸ”¥ æ­å–œï¼æ‚¨ç°åœ¨æ‹¥æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„è‚¡ç¥¨é¢„æµ‹æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼")
            print("ğŸ’¡ è¿™ä¸ªç³»ç»ŸåŒ…å«ï¼š")
            print("  ğŸ”¹ å››ç§å…ˆè¿›ç®—æ³•çš„æ€§èƒ½å¯¹æ¯”ï¼ˆéšæœºæ£®æ—ã€XGBoostã€LightGBMã€å²­å›å½’ï¼‰")
            print("  ğŸ”¹ ä¸“ä¸šçš„å…­å®«æ ¼å¯è§†åŒ–åˆ†æå›¾è¡¨")
            print("  ğŸ”¹ è¯¦ç»†çš„è´¢åŠ¡æŒ‡æ ‡é‡è¦æ€§åˆ†æ")
            print("  ğŸ”¹ å…¨é¢çš„è¯„ä¼°æŠ¥å‘Šå’ŒæŠ•èµ„å»ºè®®")
            print("  ğŸ”¹ å®é™…å¯ç”¨çš„æŠ•èµ„å†³ç­–æ”¯æŒå·¥å…·")
            print("  ğŸ”¹ å®Œæ•´çš„é£é™©æç¤ºå’Œä½¿ç”¨æŒ‡å—")
            print("ğŸ‰" * 50)
            
            return True
            
        except Exception as e:
            print(f"âŒ ç®¡é“æ‰§è¡Œå¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return False
        
        finally:
            # å…³é—­æ•°æ®åº“è¿æ¥
            if hasattr(self, 'connection'):
                self.connection.close()
                print("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¯åŠ¨è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼ˆå·¥ä½œç‰ˆæ¼”ç¤ºï¼‰")
    print("åŸºäºçœŸå®è´¢åŠ¡æ•°æ®çš„å®Œæ•´æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°")
    print("=" * 100)
    
    # åˆ›å»ºå¹¶è¿è¡Œå·¥ä½œç‰ˆæ¼”ç¤ºæ¨¡å‹
    ml_model = WorkingDemoMLModel()
    success = ml_model.run_complete_pipeline()
    
    if success:
        print("\nâœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
        print("ğŸ¯ æ‚¨å·²ç»æˆåŠŸåˆ›å»ºäº†ä¸€ä¸ªä¸“ä¸šçº§çš„æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿï¼")
        print("ğŸ’¼ ç°åœ¨æ‚¨å¯ä»¥åŸºäºè¿™ä¸ªç³»ç»Ÿè¿›è¡Œè‚¡ç¥¨æŠ•èµ„å†³ç­–åˆ†æï¼")
    else:
        print("\nâŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 