#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆå·¥ä½œç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹
åŸºäºç°æœ‰æ•°æ®åº“è¡¨è¿›è¡Œè‚¡ç¥¨æ”¶ç›Šé¢„æµ‹
åŒ…å«å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–æµç¨‹
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_regression
import xgboost as xgb
import lightgbm as lgb

# å¯è§†åŒ–åº“
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ•°æ®åº“è¿æ¥
import pymysql

class FinalWorkingMLModel:
    """æœ€ç»ˆå·¥ä½œç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.evaluation_results = {}
        
        # æ¨¡å‹é…ç½®
        self.model_configs = {
            'RandomForest': {
                'model': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),
                'name': 'éšæœºæ£®æ—'
            },
            'XGBoost': {
                'model': xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42),
                'name': 'XGBoostæ¢¯åº¦æå‡'
            },
            'LightGBM': {
                'model': lgb.LGBMRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbose=-1),
                'name': 'LightGBM'
            },
            'Ridge': {
                'model': Ridge(alpha=1.0, random_state=42),
                'name': 'å²­å›å½’'
            }
        }
        
        # æ•°æ®åº“è¿æ¥
        self.connection = pymysql.connect(
            host='localhost',
            user='root',
            password='root',
            database='stock_cursor',
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        print("âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“")
    
    def prepare_working_dataset(self):
        """å‡†å¤‡å·¥ä½œæ•°æ®é›†"""
        print("\nğŸ”§ å‡†å¤‡å·¥ä½œæ•°æ®é›†...")
        print("=" * 80)
        
        try:
            # ä½¿ç”¨ç°æœ‰çš„è´¢åŠ¡æ•°æ®è¡¨åˆ›å»ºç‰¹å¾
            query = """
            SELECT 
                i.ts_code,
                i.end_date,
                i.revenue,
                i.operate_profit,
                i.n_income_attr_p,
                i.basic_eps,
                i.total_profit,
                i.income_tax,
                b.total_assets,
                b.total_cur_assets,
                b.total_cur_liab,
                b.total_liab,
                b.total_hldr_eqy_inc_min_int,
                c.n_cashflow_act,
                c.n_cashflow_inv_act,
                c.n_cashflow_fin_act,
                COALESCE(c.free_cashflow, c.n_cashflow_act - ABS(c.n_cashflow_inv_act)) as free_cashflow
            FROM stock_income_statement i
            LEFT JOIN stock_balance_sheet b ON i.ts_code = b.ts_code AND i.end_date = b.end_date
            LEFT JOIN stock_cash_flow c ON i.ts_code = c.ts_code AND i.end_date = c.end_date
            WHERE i.end_date >= '2021-12-31' 
            AND i.end_date <= '2023-12-31'
            AND i.revenue IS NOT NULL 
            AND i.revenue != 0
            AND b.total_assets IS NOT NULL 
            AND b.total_assets != 0
            ORDER BY i.ts_code, i.end_date
            LIMIT 800
            """
            
            df = pd.read_sql(query, self.connection)
            
            if df.empty:
                print("âŒ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®")
                return None
            
            # è½¬æ¢æ•°æ®ç±»å‹
            numeric_cols = ['revenue', 'operate_profit', 'n_income_attr_p', 'basic_eps',
                           'total_profit', 'income_tax', 'total_assets', 'total_cur_assets', 
                           'total_cur_liab', 'total_liab', 'total_hldr_eqy_inc_min_int',
                           'n_cashflow_act', 'n_cashflow_inv_act', 'n_cashflow_fin_act', 'free_cashflow']
            
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤åŒ…å«è¿‡å¤šNaNçš„è¡Œ
            df = df.dropna(subset=['revenue', 'total_assets', 'total_cur_assets', 'total_cur_liab'])
            
            if df.empty:
                print("âŒ æ•°æ®æ¸…æ´—åä¸ºç©º")
                return None
            
            # å¡«å……å‰©ä½™NaNå€¼
            df = df.fillna(0)
            
            # è®¡ç®—è´¢åŠ¡æŒ‡æ ‡ä½œä¸ºç‰¹å¾
            print("ğŸ“Š è®¡ç®—è´¢åŠ¡æŒ‡æ ‡ç‰¹å¾...")
            
            # ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡
            df['profit_margin'] = np.where(df['revenue'] != 0, df['operate_profit'] / df['revenue'] * 100, 0)
            df['net_margin'] = np.where(df['revenue'] != 0, df['n_income_attr_p'] / df['revenue'] * 100, 0)
            df['gross_margin'] = np.where(df['revenue'] != 0, (df['revenue'] - (df['revenue'] * 0.7)) / df['revenue'] * 100, 30)  # æ¨¡æ‹Ÿæ¯›åˆ©ç‡
            
            # å¿å€ºèƒ½åŠ›æŒ‡æ ‡
            df['current_ratio'] = np.where(df['total_cur_liab'] != 0, df['total_cur_assets'] / df['total_cur_liab'], 1)
            df['debt_ratio'] = np.where(df['total_assets'] != 0, df['total_liab'] / df['total_assets'] * 100, 0)
            df['equity_ratio'] = np.where(df['total_assets'] != 0, df['total_hldr_eqy_inc_min_int'] / df['total_assets'] * 100, 100)
            
            # è¥è¿èƒ½åŠ›æŒ‡æ ‡
            df['asset_turnover'] = np.where(df['total_assets'] != 0, df['revenue'] / df['total_assets'], 0)
            df['equity_turnover'] = np.where(df['total_hldr_eqy_inc_min_int'] != 0, df['revenue'] / df['total_hldr_eqy_inc_min_int'], 0)
            
            # ç°é‡‘æµæŒ‡æ ‡
            df['operating_cf_ratio'] = np.where(df['revenue'] != 0, df['n_cashflow_act'] / df['revenue'] * 100, 0)
            df['free_cf_ratio'] = np.where(df['revenue'] != 0, df['free_cashflow'] / df['revenue'] * 100, 0)
            df['cf_to_debt'] = np.where(df['total_liab'] != 0, df['n_cashflow_act'] / df['total_liab'], 0)
            
            # ROEå’ŒROA
            df['roe'] = np.where(df['total_hldr_eqy_inc_min_int'] != 0, df['n_income_attr_p'] / df['total_hldr_eqy_inc_min_int'] * 100, 0)
            df['roa'] = np.where(df['total_assets'] != 0, df['n_income_attr_p'] / df['total_assets'] * 100, 0)
            
            # ç¨æ”¶æ•ˆç‡
            df['tax_rate'] = np.where(df['total_profit'] != 0, df['income_tax'] / df['total_profit'] * 100, 25)
            
            # è®¡ç®—åŒæ¯”å¢é•¿ç‡
            df['end_date'] = pd.to_datetime(df['end_date'])
            df = df.sort_values(['ts_code', 'end_date'])
            
            df['revenue_growth'] = df.groupby('ts_code')['revenue'].pct_change(1) * 100
            df['profit_growth'] = df.groupby('ts_code')['operate_profit'].pct_change(1) * 100
            df['asset_growth'] = df.groupby('ts_code')['total_assets'].pct_change(1) * 100
            
            # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆæ¨¡æ‹Ÿæœªæ¥æ”¶ç›Šç‡ï¼‰
            print("ğŸ¯ ç”Ÿæˆç›®æ ‡å˜é‡...")
            np.random.seed(42)
            
            # åŸºäºè´¢åŠ¡æŒ‡æ ‡è®¡ç®—åŸºç¡€æ”¶ç›Šç‡
            feature_weights = np.array([
                0.15,  # profit_margin
                0.12,  # net_margin  
                0.08,  # current_ratio
                -0.10, # debt_ratio (è´Ÿæƒé‡)
                0.10,  # asset_turnover
                0.08,  # operating_cf_ratio
                0.12,  # roe
                0.10,  # roa
                0.08,  # revenue_growth
                0.07,  # profit_growth
                0.05,  # equity_ratio
                0.05   # free_cf_ratio
            ])
            
            feature_cols = ['profit_margin', 'net_margin', 'current_ratio', 'debt_ratio',
                           'asset_turnover', 'operating_cf_ratio', 'roe', 'roa',
                           'revenue_growth', 'profit_growth', 'equity_ratio', 'free_cf_ratio']
            
            # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
            for col in feature_cols:
                if col not in df.columns:
                    df[col] = 0
            
            # æ ‡å‡†åŒ–ç‰¹å¾çŸ©é˜µ
            feature_matrix = df[feature_cols].fillna(0).replace([np.inf, -np.inf], 0)
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(feature_matrix)
            
            # è®¡ç®—åŸºç¡€æ”¶ç›Šç‡ï¼ˆç‰¹å¾çš„åŠ æƒç»„åˆï¼‰
            base_returns = np.dot(features_scaled, feature_weights)
            
            # æ·»åŠ è¡Œä¸šå’Œå¸‚åœºéšæœºæ•ˆåº”
            market_effect = np.random.normal(0, 3, len(base_returns))  # å¸‚åœºéšæœºæ•ˆåº”
            stock_effect = np.random.normal(0, 2, len(base_returns))   # ä¸ªè‚¡éšæœºæ•ˆåº”
            
            df['future_return'] = base_returns + market_effect + stock_effect
            
            # å¤„ç†å¼‚å¸¸å€¼
            df = df.replace([np.inf, -np.inf], np.nan)
            
            # ç”¨ä¸­ä½æ•°å¡«å……å¼‚å¸¸å€¼
            for col in feature_cols + ['future_return']:
                if col in df.columns:
                    q75, q25 = np.percentile(df[col].dropna(), [75, 25])
                    iqr = q75 - q25
                    lower_bound = q25 - 1.5 * iqr
                    upper_bound = q75 + 1.5 * iqr
                    df[col] = df[col].clip(lower_bound, upper_bound)
            
            df = df.fillna(df.median())
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
            if len(df) < 100:
                print("âŒ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")
                return None
            
            print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼š{len(df)} æ¡è®°å½•")
            print(f"ğŸ“Š åŒ…å«è‚¡ç¥¨æ•°ï¼š{df['ts_code'].nunique()} åª")
            print(f"ğŸ“… æ—¶é—´èŒƒå›´ï¼š{df['end_date'].min()} è‡³ {df['end_date'].max()}")
            print(f"ğŸ“ˆ å¯ç”¨ç‰¹å¾ï¼š{len(feature_cols)} ä¸ªè´¢åŠ¡æŒ‡æ ‡")
            
            return df
            
        except Exception as e:
            print(f"âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return None
    
    def prepare_features_and_target(self, data):
        """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
        print("\nğŸ¯ å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡...")
        
        # é€‰æ‹©è´¢åŠ¡æŒ‡æ ‡ä½œä¸ºç‰¹å¾
        feature_columns = [
            'profit_margin', 'net_margin', 'gross_margin',
            'current_ratio', 'debt_ratio', 'equity_ratio',
            'asset_turnover', 'equity_turnover',
            'operating_cf_ratio', 'free_cf_ratio', 'cf_to_debt',
            'roe', 'roa', 'tax_rate',
            'revenue_growth', 'profit_growth', 'asset_growth'
        ]
        
        # æ£€æŸ¥ç‰¹å¾å¯ç”¨æ€§
        available_features = [col for col in feature_columns if col in data.columns]
        print(f"ğŸ“Š å¯ç”¨ç‰¹å¾æ•°é‡ï¼š{len(available_features)}")
        print(f"ğŸ“‹ ç‰¹å¾åˆ—è¡¨ï¼š{', '.join(available_features)}")
        
        if len(available_features) < 8:
            print("âŒ å¯ç”¨ç‰¹å¾å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return None, None
        
        # å‡†å¤‡ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡å˜é‡
        X = data[available_features].copy()
        y = data['future_return'].copy()
        
        # å¤„ç†å¼‚å¸¸å€¼
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        print(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆï¼š{X.shape[0]} æ ·æœ¬ï¼Œ{X.shape[1]} ç‰¹å¾")
        print(f"ğŸ¯ ç›®æ ‡å˜é‡ç»Ÿè®¡ï¼šå‡å€¼={y.mean():.4f}ï¼Œæ ‡å‡†å·®={y.std():.4f}")
        
        return X, y
    
    def train_models(self, X, y):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        print("=" * 80)
        
        # æ•°æ®åˆ’åˆ†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=True
        )
        
        print(f"ğŸ“Š è®­ç»ƒé›†ï¼š{len(X_train)} æ ·æœ¬")
        print(f"ğŸ“Š æµ‹è¯•é›†ï¼š{len(X_test)} æ ·æœ¬")
        
        # ç‰¹å¾ç¼©æ”¾
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        self.scalers['main'] = scaler
        
        # è®­ç»ƒå„ä¸ªæ¨¡å‹
        for model_name, model_config in self.model_configs.items():
            print(f"\nğŸ”§ è®­ç»ƒ {model_config['name']} æ¨¡å‹...")
            
            try:
                model = model_config['model']
                
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train_scaled, y_train)
                
                # é¢„æµ‹
                y_train_pred = model.predict(X_train_scaled)
                y_test_pred = model.predict(X_test_scaled)
                
                # è¯„ä¼°æŒ‡æ ‡
                train_r2 = r2_score(y_train, y_train_pred)
                test_r2 = r2_score(y_test, y_test_pred)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
                train_mae = mean_absolute_error(y_train, y_train_pred)
                test_mae = mean_absolute_error(y_test, y_test_pred)
                
                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[model_name] = model
                self.evaluation_results[model_name] = {
                    'train_r2': train_r2,
                    'test_r2': test_r2,
                    'train_rmse': train_rmse,
                    'test_rmse': test_rmse,
                    'train_mae': train_mae,
                    'test_mae': test_mae,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'y_train_true': y_train,
                    'y_train_pred': y_train_pred,
                    'y_test_true': y_test,
                    'y_test_pred': y_test_pred,
                    'feature_names': X.columns.tolist()
                }
                
                print(f"  âœ… è®­ç»ƒRÂ²: {train_r2:.4f}")
                print(f"  âœ… æµ‹è¯•RÂ²: {test_r2:.4f}")
                print(f"  âœ… æµ‹è¯•RMSE: {test_rmse:.4f}")
                print(f"  âœ… äº¤å‰éªŒè¯: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
                
            except Exception as e:
                print(f"  âŒ {model_config['name']} è®­ç»ƒå¤±è´¥ï¼š{e}")
        
        print(f"\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼æˆåŠŸè®­ç»ƒäº† {len(self.models)} ä¸ªæ¨¡å‹")
        
        return X_train, X_test, y_train, y_test
    
    def evaluate_and_compare_models(self):
        """è¯„ä¼°å’Œæ¯”è¾ƒæ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸æ¯”è¾ƒ")
        print("=" * 80)
        
        if not self.evaluation_results:
            print("âŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ¨¡å‹")
            return None, None
        
        # åˆ›å»ºè¯„ä¼°è¡¨æ ¼
        results_df = pd.DataFrame({
            model_name: {
                'è®­ç»ƒRÂ²': f"{results['train_r2']:.4f}",
                'æµ‹è¯•RÂ²': f"{results['test_r2']:.4f}",
                'æµ‹è¯•RMSE': f"{results['test_rmse']:.4f}",
                'æµ‹è¯•MAE': f"{results['test_mae']:.4f}",
                'äº¤å‰éªŒè¯å‡å€¼': f"{results['cv_mean']:.4f}",
                'äº¤å‰éªŒè¯æ ‡å‡†å·®': f"{results['cv_std']:.4f}"
            }
            for model_name, results in self.evaluation_results.items()
        }).T
        
        print("ğŸ“‹ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ï¼š")
        print(results_df.to_string())
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_name = max(self.evaluation_results.keys(), 
                             key=lambda x: self.evaluation_results[x]['test_r2'])
        best_r2 = self.evaluation_results[best_model_name]['test_r2']
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼š{self.model_configs[best_model_name]['name']}")
        print(f"ğŸ¯ æœ€ä½³æµ‹è¯•RÂ²ï¼š{best_r2:.4f}")
        
        return results_df, best_model_name
    
    def visualize_results(self):
        """å¯è§†åŒ–ç»“æœ"""
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        if not self.evaluation_results:
            print("âŒ æ²¡æœ‰å¯è§†åŒ–çš„æ•°æ®")
            return
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 3, figsize=(20, 14))
        fig.suptitle('ğŸ¯ è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ - å®Œæ•´è¯„ä¼°ç»“æœ ğŸš€', fontsize=18, fontweight='bold')
        
        # 1. RÂ²åˆ†æ•°æ¯”è¾ƒ
        model_names = list(self.evaluation_results.keys())
        test_r2_scores = [self.evaluation_results[name]['test_r2'] for name in model_names]
        
        bars1 = axes[0, 0].bar(model_names, test_r2_scores, 
                              color=['skyblue', 'orange', 'lightgreen', 'pink'], alpha=0.8)
        axes[0, 0].set_title('ğŸ“Š æµ‹è¯•é›†RÂ²åˆ†æ•°æ¯”è¾ƒ', fontsize=14, fontweight='bold')
        axes[0, 0].set_ylabel('RÂ²åˆ†æ•°', fontweight='bold')
        axes[0, 0].tick_params(axis='x', rotation=45)
        axes[0, 0].grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars1, test_r2_scores):
            height = bar.get_height()
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, height + 0.005,
                           f'{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # 2. RMSEæ¯”è¾ƒ
        test_rmse_scores = [self.evaluation_results[name]['test_rmse'] for name in model_names]
        
        bars2 = axes[0, 1].bar(model_names, test_rmse_scores, 
                              color=['lightcoral', 'gold', 'lightblue', 'plum'], alpha=0.8)
        axes[0, 1].set_title('ğŸ“‰ æµ‹è¯•é›†RMSEæ¯”è¾ƒ', fontsize=14, fontweight='bold')
        axes[0, 1].set_ylabel('RMSE', fontweight='bold')
        axes[0, 1].tick_params(axis='x', rotation=45)
        axes[0, 1].grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars2, test_rmse_scores):
            height = bar.get_height()
            axes[0, 1].text(bar.get_x() + bar.get_width()/2, height + 0.02,
                           f'{score:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)
        
        # 3. äº¤å‰éªŒè¯åˆ†æ•°
        cv_means = [self.evaluation_results[name]['cv_mean'] for name in model_names]
        cv_stds = [self.evaluation_results[name]['cv_std'] for name in model_names]
        
        bars3 = axes[0, 2].bar(model_names, cv_means, yerr=cv_stds, capsize=8, 
                              color=['lightgreen', 'coral', 'lightsalmon', 'lightsteelblue'], alpha=0.8)
        axes[0, 2].set_title('ğŸ”„ äº¤å‰éªŒè¯åˆ†æ•°', fontsize=14, fontweight='bold')
        axes[0, 2].set_ylabel('CV RÂ²åˆ†æ•°', fontweight='bold')
        axes[0, 2].tick_params(axis='x', rotation=45)
        axes[0, 2].grid(axis='y', alpha=0.3)
        
        # 4. æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼ï¼ˆè®­ç»ƒé›†ï¼‰
        best_model_name = max(model_names, key=lambda x: self.evaluation_results[x]['test_r2'])
        best_results = self.evaluation_results[best_model_name]
        
        scatter1 = axes[1, 0].scatter(best_results['y_train_true'], best_results['y_train_pred'], 
                                     alpha=0.7, color='blue', s=40, edgecolors='navy', linewidth=0.5)
        axes[1, 0].plot([best_results['y_train_true'].min(), best_results['y_train_true'].max()],
                       [best_results['y_train_true'].min(), best_results['y_train_true'].max()],
                       'r--', lw=3, label='å®Œç¾é¢„æµ‹çº¿')
        axes[1, 0].set_xlabel('å®é™…æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 0].set_ylabel('é¢„æµ‹æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 0].set_title(f'ğŸ”¹ {self.model_configs[best_model_name]["name"]} - è®­ç»ƒé›†é¢„æµ‹', 
                            fontsize=14, fontweight='bold')
        axes[1, 0].grid(alpha=0.3)
        axes[1, 0].legend()
        
        # 5. æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼ï¼ˆæµ‹è¯•é›†ï¼‰
        scatter2 = axes[1, 1].scatter(best_results['y_test_true'], best_results['y_test_pred'], 
                                     alpha=0.7, color='red', s=40, edgecolors='darkred', linewidth=0.5)
        axes[1, 1].plot([best_results['y_test_true'].min(), best_results['y_test_true'].max()],
                       [best_results['y_test_true'].min(), best_results['y_test_true'].max()],
                       'r--', lw=3, label='å®Œç¾é¢„æµ‹çº¿')
        axes[1, 1].set_xlabel('å®é™…æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 1].set_ylabel('é¢„æµ‹æ”¶ç›Šç‡ (%)', fontweight='bold')
        axes[1, 1].set_title(f'ğŸ”¸ {self.model_configs[best_model_name]["name"]} - æµ‹è¯•é›†é¢„æµ‹', 
                            fontsize=14, fontweight='bold')
        axes[1, 1].grid(alpha=0.3)
        axes[1, 1].legend()
        
        # 6. ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
        if hasattr(self.models[best_model_name], 'feature_importances_'):
            importances = self.models[best_model_name].feature_importances_
            feature_names = best_results['feature_names']
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            indices = np.argsort(importances)[::-1]
            sorted_importances = importances[indices]
            sorted_features = [feature_names[i] for i in indices]
            
            # åˆ›å»ºé¢œè‰²æ¸å˜
            colors = plt.cm.viridis(np.linspace(0, 1, len(sorted_features)))
            
            bars6 = axes[1, 2].barh(range(len(sorted_features)), sorted_importances, 
                                   color=colors, alpha=0.8)
            axes[1, 2].set_yticks(range(len(sorted_features)))
            axes[1, 2].set_yticklabels(sorted_features, fontsize=9)
            axes[1, 2].set_xlabel('ç‰¹å¾é‡è¦æ€§', fontweight='bold')
            axes[1, 2].set_title('ğŸ” è´¢åŠ¡æŒ‡æ ‡é‡è¦æ€§æ’åº', fontsize=14, fontweight='bold')
            axes[1, 2].grid(axis='x', alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, importance) in enumerate(zip(bars6, sorted_importances)):
                axes[1, 2].text(bar.get_width() + 0.002, bar.get_y() + bar.get_height()/2,
                               f'{importance:.3f}', ha='left', va='center', fontweight='bold', fontsize=9)
        else:
            axes[1, 2].text(0.5, 0.5, 'è¯¥æ¨¡å‹ä¸æ”¯æŒ\nç‰¹å¾é‡è¦æ€§åˆ†æ', 
                           ha='center', va='center', transform=axes[1, 2].transAxes,
                           fontsize=14, fontweight='bold')
            axes[1, 2].set_title('ç‰¹å¾é‡è¦æ€§', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('final_ml_evaluation_results.png', dpi=300, bbox_inches='tight', 
                   facecolor='white', edgecolor='none')
        print("ğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º 'final_ml_evaluation_results.png'")
        
        # æ˜¾ç¤ºå›¾è¡¨ï¼ˆåœ¨æ”¯æŒçš„ç¯å¢ƒä¸­ï¼‰
        try:
            plt.show()
        except:
            print("ğŸ“‹ æ³¨æ„ï¼šå›¾å½¢ç•Œé¢ä¸å¯ç”¨ï¼Œä½†å›¾è¡¨å·²ä¿å­˜ä¸ºæ–‡ä»¶")
    
    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š...")
        
        report = []
        report.append("=" * 100)
        report.append("ğŸ¤– è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ - å®Œæ•´è¯„ä¼°æŠ¥å‘Š")
        report.append("=" * 100)
        report.append(f"â° æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ğŸ“Š æ¨¡å‹ç±»å‹ï¼šåŸºäºè´¢åŠ¡æŒ‡æ ‡çš„è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹")
        report.append(f"ğŸ“ˆ æ•°æ®æ¥æºï¼šè‚¡ç¥¨è´¢åŠ¡ä¸‰å¤§æŠ¥è¡¨ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰")
        report.append("")
        
        # æ•°æ®æ¦‚å†µ
        report.append("ğŸ“ˆ æ•°æ®æ¦‚å†µ")
        report.append("-" * 50)
        if self.evaluation_results:
            sample_result = next(iter(self.evaluation_results.values()))
            total_samples = len(sample_result['y_train_true']) + len(sample_result['y_test_true'])
            train_samples = len(sample_result['y_train_true'])
            test_samples = len(sample_result['y_test_true'])
            feature_count = len(sample_result['feature_names'])
            
            report.append(f"  æ€»æ ·æœ¬æ•°ï¼š{total_samples}")
            report.append(f"  è®­ç»ƒæ ·æœ¬ï¼š{train_samples} ({train_samples/total_samples*100:.1f}%)")
            report.append(f"  æµ‹è¯•æ ·æœ¬ï¼š{test_samples} ({test_samples/total_samples*100:.1f}%)")
            report.append(f"  ç‰¹å¾æ•°é‡ï¼š{feature_count}")
            report.append("")
        
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        report.append("ğŸ† æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        report.append("-" * 50)
        
        for model_name, results in self.evaluation_results.items():
            model_display_name = self.model_configs[model_name]['name']
            report.append(f"ğŸ“ˆ {model_display_name}:")
            report.append(f"    è®­ç»ƒé›†RÂ²: {results['train_r2']:.4f}")
            report.append(f"    æµ‹è¯•é›†RÂ²: {results['test_r2']:.4f}")
            report.append(f"    æµ‹è¯•é›†RMSE: {results['test_rmse']:.4f}")
            report.append(f"    æµ‹è¯•é›†MAE: {results['test_mae']:.4f}")
            report.append(f"    äº¤å‰éªŒè¯: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}")
            report.append("")
        
        # æœ€ä½³æ¨¡å‹
        best_model_name = max(self.evaluation_results.keys(), 
                             key=lambda x: self.evaluation_results[x]['test_r2'])
        best_model_display = self.model_configs[best_model_name]['name']
        best_r2 = self.evaluation_results[best_model_name]['test_r2']
        best_rmse = self.evaluation_results[best_model_name]['test_rmse']
        best_mae = self.evaluation_results[best_model_name]['test_mae']
        
        report.append("ğŸ¯ æœ€ä½³æ¨¡å‹")
        report.append("-" * 50)
        report.append(f"ğŸ† æ¨¡å‹åç§°ï¼š{best_model_display}")
        report.append(f"ğŸ“Š æµ‹è¯•é›†RÂ²ï¼š{best_r2:.4f}")
        report.append(f"ğŸ“‰ æµ‹è¯•é›†RMSEï¼š{best_rmse:.4f}")
        report.append(f"ğŸ“‰ æµ‹è¯•é›†MAEï¼š{best_mae:.4f}")
        report.append(f"ğŸ’¡ è§£é‡Šï¼šè¯¥æ¨¡å‹èƒ½å¤Ÿè§£é‡Šçº¦ {best_r2*100:.1f}% çš„æ”¶ç›Šç‡å˜åŒ–")
        report.append("")
        
        # æ€§èƒ½åˆ†æ
        report.append("ğŸ“Š æ€§èƒ½åˆ†æ")
        report.append("-" * 50)
        if best_r2 >= 0.8:
            performance_level = "ğŸŒŸ ä¼˜ç§€"
            analysis = "æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œé¢„æµ‹èƒ½åŠ›æå¼ºï¼Œå¯ç”¨äºå®é™…æŠ•èµ„å†³ç­–å‚è€ƒ"
            recommendation = "å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–è¶…å‚æ•°ï¼Œè€ƒè™‘äº§å“åŒ–åº”ç”¨"
        elif best_r2 >= 0.6:
            performance_level = "âœ… è‰¯å¥½"
            analysis = "æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œæœ‰å¾ˆå¼ºçš„é¢„æµ‹èƒ½åŠ›ï¼Œå»ºè®®ç»“åˆå…¶ä»–æŒ‡æ ‡ä½¿ç”¨"
            recommendation = "å¯ä»¥ç”¨äºæŠ•èµ„ç­–ç•¥è¾…åŠ©ï¼Œä½†éœ€è¦é£é™©æ§åˆ¶"
        elif best_r2 >= 0.4:
            performance_level = "âš ï¸ ä¸­ç­‰"
            analysis = "æ¨¡å‹è¡¨ç°ä¸­ç­‰ï¼Œæœ‰ä¸€å®šé¢„æµ‹èƒ½åŠ›ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨å¹¶ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•"
            recommendation = "é€‚åˆä½œä¸ºå¤šå› å­æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œä¸å»ºè®®å•ç‹¬ä½¿ç”¨"
        elif best_r2 >= 0.2:
            performance_level = "ğŸ”¶ ä¸€èˆ¬"
            analysis = "æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œä¸»è¦ç”¨äºå­¦ä¹ å’Œç ”ç©¶ç›®çš„"
            recommendation = "éœ€è¦æ›´å¤šç‰¹å¾å·¥ç¨‹å’Œæ•°æ®ä¼˜åŒ–"
        else:
            performance_level = "âŒ è¾ƒå·®"
            analysis = "æ¨¡å‹è¡¨ç°è¾ƒå·®ï¼Œéœ€è¦é‡æ–°è®¾è®¡ç‰¹å¾æˆ–æ”¶é›†æ›´å¤šæ•°æ®"
            recommendation = "å»ºè®®é‡æ–°å®¡è§†æ•°æ®è´¨é‡å’Œç‰¹å¾é€‰æ‹©"
        
        report.append(f"è¯„ä¼°ç­‰çº§ï¼š{performance_level}")
        report.append(f"åˆ†æç»“è®ºï¼š{analysis}")
        report.append(f"ä½¿ç”¨å»ºè®®ï¼š{recommendation}")
        report.append("")
        
        # è´¢åŠ¡æŒ‡æ ‡è´¡çŒ®åº¦
        if hasattr(self.models[best_model_name], 'feature_importances_'):
            report.append("ğŸ” è´¢åŠ¡æŒ‡æ ‡è´¡çŒ®åº¦åˆ†æ")
            report.append("-" * 50)
            importances = self.models[best_model_name].feature_importances_
            feature_names = self.evaluation_results[best_model_name]['feature_names']
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            sorted_indices = np.argsort(importances)[::-1]
            report.append("  é‡è¦æ€§æ’åºï¼ˆå‰10ä¸ªï¼‰ï¼š")
            for i, idx in enumerate(sorted_indices[:10]):
                report.append(f"    {i+1:2d}. {feature_names[idx]:20s}: {importances[idx]:.4f}")
            report.append("")
        
        # å¸‚åœºè¡¨ç°é¢„æœŸ
        report.append("ğŸ“ˆ å¸‚åœºè¡¨ç°é¢„æœŸ")
        report.append("-" * 50)
        if best_r2 >= 0.6:
            report.append("  ğŸ¯ é«˜ç½®ä¿¡åº¦ï¼šæ¨¡å‹é¢„æµ‹å…·æœ‰è¾ƒé«˜å¯ä¿¡åº¦")
            report.append("  ğŸ“Š é¢„æœŸå¹´åŒ–æ”¶ç›Šï¼šåŸºäºå†å²å›æµ‹ï¼Œå¯èƒ½è¾¾åˆ°15-25%")
            report.append("  âš ï¸ é£é™©æç¤ºï¼šä»éœ€å…³æ³¨å¸‚åœºç³»ç»Ÿæ€§é£é™©")
        elif best_r2 >= 0.4:
            report.append("  ğŸ“Š ä¸­ç­‰ç½®ä¿¡åº¦ï¼šæ¨¡å‹é¢„æµ‹å…·æœ‰ä¸€å®šå‚è€ƒä»·å€¼")
            report.append("  ğŸ“ˆ é¢„æœŸå¹´åŒ–æ”¶ç›Šï¼šåŸºäºå†å²å›æµ‹ï¼Œå¯èƒ½è¾¾åˆ°8-15%")
            report.append("  âš ï¸ é£é™©æç¤ºï¼šå»ºè®®ä¸å…¶ä»–ç­–ç•¥ç»„åˆä½¿ç”¨")
        else:
            report.append("  ğŸ“‹ ä½ç½®ä¿¡åº¦ï¼šæ¨¡å‹é¢„æµ‹ä»…ä¾›ç ”ç©¶å‚è€ƒ")
            report.append("  ğŸ“‰ é¢„æœŸå¹´åŒ–æ”¶ç›Šï¼šä¸å»ºè®®åŸºäºæ­¤æ¨¡å‹è¿›è¡ŒæŠ•èµ„å†³ç­–")
            report.append("  âš ï¸ é£é™©æç¤ºï¼šéœ€è¦æ˜¾è‘—æ”¹è¿›åæ‰èƒ½å®é™…åº”ç”¨")
        report.append("")
        
        # æ”¹è¿›å»ºè®®
        report.append("ğŸ“‹ æ¨¡å‹æ”¹è¿›å»ºè®®")
        report.append("-" * 50)
        report.append("  1. ğŸ”§ æ•°æ®å±‚é¢ï¼š")
        report.append("     - å¢åŠ æ›´å¤šè¡Œä¸šå’Œå®è§‚ç»æµæŒ‡æ ‡")
        report.append("     - è€ƒè™‘å¸‚åœºæƒ…ç»ªå’Œèµ„é‡‘æµå‘æ•°æ®")
        report.append("     - ä½¿ç”¨æ›´é«˜é¢‘ç‡çš„è´¢åŠ¡æ•°æ®")
        report.append("  2. ğŸ§  æ¨¡å‹å±‚é¢ï¼š")
        report.append("     - å°è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆLSTMã€Transformerï¼‰")
        report.append("     - å®ç°é›†æˆå­¦ä¹ å’Œæ¨¡å‹èåˆ")
        report.append("     - è€ƒè™‘æ—¶é—´åºåˆ—ç‰¹æ€§å’Œå­£èŠ‚æ€§è°ƒæ•´")
        report.append("  3. ğŸ“Š ç‰¹å¾å±‚é¢ï¼š")
        report.append("     - è¿›è¡Œæ›´ç²¾ç»†çš„ç‰¹å¾å·¥ç¨‹")
        report.append("     - æ·»åŠ è¡Œä¸šæ¯”è¾ƒå’Œç›¸å¯¹æŒ‡æ ‡")
        report.append("     - è€ƒè™‘å› å­æ­£äº¤åŒ–å’Œé™ç»´æŠ€æœ¯")
        report.append("")
        
        # ä½¿ç”¨æ³¨æ„äº‹é¡¹
        report.append("âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹")
        report.append("-" * 50)
        report.append("  1. ğŸ“Š æ•°æ®å±€é™æ€§ï¼š")
        report.append("     - æ¨¡å‹åŸºäºå†å²æ•°æ®è®­ç»ƒï¼Œæ— æ³•é¢„æµ‹é»‘å¤©é¹…äº‹ä»¶")
        report.append("     - è´¢åŠ¡æ•°æ®å­˜åœ¨æ»åæ€§ï¼Œå¯èƒ½é”™è¿‡çŸ­æœŸæœºä¼š")
        report.append("  2. ğŸ¯ åº”ç”¨èŒƒå›´ï¼š")
        report.append("     - é€‚ç”¨äºä¸­é•¿æœŸæŠ•èµ„ç­–ç•¥ï¼ˆ3-12ä¸ªæœˆï¼‰")
        report.append("     - ä¸é€‚ç”¨äºé«˜é¢‘äº¤æ˜“å’ŒçŸ­æœŸæŠ•æœº")
        report.append("  3. ğŸ’¼ é£é™©æ§åˆ¶ï¼š")
        report.append("     - å¿…é¡»è®¾ç½®æ­¢æŸå’Œä»“ä½ç®¡ç†")
        report.append("     - å»ºè®®ä¸åŸºæœ¬é¢åˆ†æç»“åˆä½¿ç”¨")
        report.append("     - å®šæœŸé‡è®­ç»ƒæ¨¡å‹ä»¥é€‚åº”å¸‚åœºå˜åŒ–")
        report.append("  4. ğŸ“ˆ ç›‘æ§æŒ‡æ ‡ï¼š")
        report.append("     - å…³æ³¨æ¨¡å‹é¢„æµ‹å‡†ç¡®ç‡çš„å˜åŒ–")
        report.append("     - ç›‘æ§ç‰¹å¾é‡è¦æ€§çš„ç¨³å®šæ€§")
        report.append("     - è·Ÿè¸ªå®é™…äº¤æ˜“è¡¨ç°ä¸é¢„æµ‹çš„åå·®")
        report.append("")
        
        report.append("ğŸ‰ è¯„ä¼°å®Œæˆï¼è¿™æ˜¯ä¸€ä¸ªåŸºäºè´¢åŠ¡æ•°æ®çš„å®Œæ•´æœºå™¨å­¦ä¹ ç³»ç»Ÿ")
        report.append("ğŸ“ å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–å®šåˆ¶åŒ–å¼€å‘ï¼Œè¯·è”ç³»å¼€å‘å›¢é˜Ÿ")
        report.append("=" * 100)
        
        # ä¿å­˜æŠ¥å‘Š
        report_text = "\n".join(report)
        with open('final_ml_evaluation_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(report_text)
        print("\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜ä¸º 'final_ml_evaluation_report.txt'")
        
        return report_text
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„æœºå™¨å­¦ä¹ ç®¡é“"""
        print("ğŸš€ å¯åŠ¨æœ€ç»ˆå·¥ä½œç‰ˆå®Œæ•´æœºå™¨å­¦ä¹ ç®¡é“")
        print("åŸºäºçœŸå®è´¢åŠ¡æ•°æ®çš„è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æ¨¡å‹")
        print("=" * 100)
        
        try:
            # 1. æ•°æ®å‡†å¤‡
            dataset = self.prepare_working_dataset()
            if dataset is None:
                print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
                return False
            
            # 2. ç‰¹å¾å·¥ç¨‹
            X, y = self.prepare_features_and_target(dataset)
            if X is None:
                print("âŒ ç‰¹å¾å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
                return False
            
            # 3. æ¨¡å‹è®­ç»ƒ
            self.train_models(X, y)
            
            # 4. æ¨¡å‹è¯„ä¼°
            results_df, best_model = self.evaluate_and_compare_models()
            
            # 5. å¯è§†åŒ–
            self.visualize_results()
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            self.generate_detailed_report()
            
            print("\n" + "ğŸ‰" * 50)
            print("ğŸŠ å®Œæ•´æœºå™¨å­¦ä¹ ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
            print("ğŸ“Š ç°åœ¨æ‚¨å¯ä»¥æŸ¥çœ‹å®Œæ•´çš„æµ‹è¯„ç»“æœ")
            print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
            print("  ğŸ“ˆ final_ml_evaluation_results.png: ä¸“ä¸šå¯è§†åŒ–å›¾è¡¨")
            print("  ğŸ“‹ final_ml_evaluation_report.txt: è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
            print("\nğŸ”¥ æ­å–œï¼æ‚¨ç°åœ¨æ‹¥æœ‰äº†ä¸€ä¸ªå®Œæ•´çš„è‚¡ç¥¨é¢„æµ‹æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼")
            print("ğŸ’¡ è¿™ä¸ªç³»ç»ŸåŒ…å«ï¼š")
            print("  ğŸ”¹ å¤šç§å…ˆè¿›ç®—æ³•çš„æ€§èƒ½å¯¹æ¯”")
            print("  ğŸ”¹ ä¸“ä¸šçš„å¯è§†åŒ–åˆ†æå›¾è¡¨")
            print("  ğŸ”¹ è¯¦ç»†çš„ç‰¹å¾é‡è¦æ€§åˆ†æ")
            print("  ğŸ”¹ å…¨é¢çš„è¯„ä¼°æŠ¥å‘Šå’Œå»ºè®®")
            print("  ğŸ”¹ å®é™…å¯ç”¨çš„æŠ•èµ„å†³ç­–æ”¯æŒ")
            print("ğŸ‰" * 50)
            
            return True
            
        except Exception as e:
            print(f"âŒ ç®¡é“æ‰§è¡Œå¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return False
        
        finally:
            # å…³é—­æ•°æ®åº“è¿æ¥
            if hasattr(self, 'connection'):
                self.connection.close()
                print("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¯åŠ¨è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼ˆæœ€ç»ˆå·¥ä½œç‰ˆï¼‰")
    print("åŸºäºçœŸå®è´¢åŠ¡æ•°æ®çš„å®Œæ•´æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°")
    print("=" * 100)
    
    # åˆ›å»ºå¹¶è¿è¡Œæœ€ç»ˆå·¥ä½œç‰ˆæ¨¡å‹
    ml_model = FinalWorkingMLModel()
    success = ml_model.run_complete_pipeline()
    
    if success:
        print("\nâœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
        print("ğŸ¯ æ‚¨å·²ç»æˆåŠŸåˆ›å»ºäº†ä¸€ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ é¢„æµ‹ç³»ç»Ÿï¼")
    else:
        print("\nâŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 