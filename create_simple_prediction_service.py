#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ›å»ºç®€åŒ–çš„é¢„æµ‹æœåŠ¡ï¼Œç”¨äºæ¼”ç¤ºæ¨¡å‹çš„é¢„æµ‹åŠŸèƒ½
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app import create_app
from app.extensions import db
from app.models import FactorValues, MLModelDefinition, MLPredictions
import pandas as pd
import numpy as np
import joblib
from datetime import datetime

def create_simple_prediction_service():
    """åˆ›å»ºç®€åŒ–çš„é¢„æµ‹æœåŠ¡"""
    app = create_app()
    
    with app.app_context():
        print("ğŸ”® åˆ›å»ºç®€åŒ–çš„é¢„æµ‹æœåŠ¡")
        print("=" * 60)
        
        try:
            # 1. åŠ è½½æ¨¡å‹
            print("ğŸ“¥ åŠ è½½æ¨¡å‹...")
            model_path = 'models/simple_demo_model.pkl'
            scaler_path = 'models/simple_demo_scaler.pkl'
            
            if not os.path.exists(model_path):
                print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ create_simple_demo_model.py")
                return
            
            model = joblib.load(model_path)
            scaler = joblib.load(scaler_path)
            print("   âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # 2. è·å–æœ€æ–°çš„å› å­æ•°æ®
            print("ğŸ“Š è·å–æœ€æ–°å› å­æ•°æ®...")
            factor_data = pd.read_sql('''
                SELECT ts_code, factor_id, factor_value
                FROM factor_values
                WHERE factor_id IN ('chip_concentration', 'money_flow_strength')
            ''', db.engine)
            
            # åˆ›å»ºç‰¹å¾çŸ©é˜µ
            feature_df = factor_data.pivot_table(
                index='ts_code',
                columns='factor_id',
                values='factor_value',
                aggfunc='first'
            ).reset_index()
            
            feature_df = feature_df.dropna()
            print(f"   å¯é¢„æµ‹è‚¡ç¥¨æ•°é‡: {len(feature_df)}")
            
            # 3. è¿›è¡Œé¢„æµ‹
            print("ğŸš€ è¿›è¡Œé¢„æµ‹...")
            X = feature_df[['chip_concentration', 'money_flow_strength']].values
            X_scaled = scaler.transform(X)
            predictions = model.predict(X_scaled)
            
            # 4. åˆ›å»ºé¢„æµ‹ç»“æœ
            print("ğŸ“ ä¿å­˜é¢„æµ‹ç»“æœ...")
            current_date = datetime.now().strftime('%Y-%m-%d')
            
            # æ¸…é™¤æ—§çš„é¢„æµ‹ç»“æœ
            MLPredictions.query.filter_by(
                model_id='simple_demo_model',
                trade_date=current_date
            ).delete()
            
            # ä¿å­˜æ–°çš„é¢„æµ‹ç»“æœ
            prediction_results = []
            for i, ts_code in enumerate(feature_df['ts_code']):
                pred_result = MLPredictions(
                    model_id='simple_demo_model',
                    ts_code=ts_code,
                    trade_date=current_date,
                    predicted_return=float(predictions[i]),
                    probability_score=float((predictions[i] - predictions.min()) / (predictions.max() - predictions.min())),
                    rank_score=int(len(predictions) - np.argsort(np.argsort(predictions))[i])
                )
                prediction_results.append(pred_result)
            
            db.session.add_all(prediction_results)
            db.session.commit()
            
            print(f"   âœ… ä¿å­˜äº† {len(prediction_results)} æ¡é¢„æµ‹ç»“æœ")
            
            # 5. æ˜¾ç¤ºé¢„æµ‹ç»Ÿè®¡
            print("\nğŸ“Š é¢„æµ‹ç»Ÿè®¡:")
            print(f"   é¢„æµ‹æ”¶ç›Šç‡èŒƒå›´: {predictions.min():.4f} è‡³ {predictions.max():.4f}")
            print(f"   é¢„æµ‹æ”¶ç›Šç‡å‡å€¼: {predictions.mean():.4f}")
            print(f"   é¢„æµ‹æ”¶ç›Šç‡æ ‡å‡†å·®: {predictions.std():.4f}")
            
            # 6. æ˜¾ç¤ºå‰10åè‚¡ç¥¨
            print("\nğŸ† é¢„æµ‹æ”¶ç›Šç‡å‰10åè‚¡ç¥¨:")
            top_indices = np.argsort(predictions)[-10:][::-1]
            
            for i, idx in enumerate(top_indices):
                ts_code = feature_df.iloc[idx]['ts_code']
                pred_return = predictions[idx]
                chip_conc = feature_df.iloc[idx]['chip_concentration']
                money_flow = feature_df.iloc[idx]['money_flow_strength']
                
                print(f"   {i+1:2d}. {ts_code}: {pred_return:+.4f} (ç­¹ç é›†ä¸­åº¦: {chip_conc:.4f}, èµ„é‡‘æµå¼ºåº¦: {money_flow:.4f})")
            
            print("\nâœ… ç®€åŒ–é¢„æµ‹æœåŠ¡åˆ›å»ºå®Œæˆï¼")
            print("ğŸ¯ ç°åœ¨æ‚¨å¯ä»¥åœ¨Webç•Œé¢çš„'æ¨¡å‹ç®¡ç†'é¡µé¢ä¸­:")
            print("   1. æŸ¥çœ‹ 'simple_demo_model' æ¨¡å‹")
            print("   2. ç‚¹å‡»'é¢„æµ‹'æŒ‰é’®è¿›è¡Œé¢„æµ‹")
            print("   3. æŸ¥çœ‹é¢„æµ‹ç»“æœå’Œæ’å")
            
        except Exception as e:
            print(f"âŒ åˆ›å»ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    create_simple_prediction_service() 