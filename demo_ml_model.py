#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¼”ç¤ºç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹
åŸºäºæŠ€æœ¯å› å­æ•°æ®è¿›è¡Œè‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æ¼”ç¤º
åŒ…å«å®Œæ•´çš„è®­ç»ƒã€è¯„ä¼°å’Œå¯è§†åŒ–æµç¨‹
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# æœºå™¨å­¦ä¹ åº“
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.feature_selection import SelectKBest, f_regression
import xgboost as xgb
import lightgbm as lgb

# å¯è§†åŒ–åº“
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# æ•°æ®åº“è¿æ¥
import pymysql

class DemoMLModel:
    """æ¼”ç¤ºç‰ˆæœºå™¨å­¦ä¹ æ¨¡å‹"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.evaluation_results = {}
        
        # æ¨¡å‹é…ç½®
        self.model_configs = {
            'RandomForest': {
                'model': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),
                'name': 'éšæœºæ£®æ—'
            },
            'XGBoost': {
                'model': xgb.XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42),
                'name': 'XGBoostæ¢¯åº¦æå‡'
            },
            'LightGBM': {
                'model': lgb.LGBMRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbose=-1),
                'name': 'LightGBM'
            },
            'Ridge': {
                'model': Ridge(alpha=1.0, random_state=42),
                'name': 'å²­å›å½’'
            }
        }
        
        # æ•°æ®åº“è¿æ¥
        self.connection = pymysql.connect(
            host='localhost',
            user='root',
            password='root',
            database='stock_cursor',
            charset='utf8mb4',
            cursorclass=pymysql.cursors.DictCursor
        )
        print("âœ… æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“")
    
    def prepare_demo_dataset(self):
        """å‡†å¤‡æ¼”ç¤ºæ•°æ®é›†"""
        print("\nğŸ”§ å‡†å¤‡æ¼”ç¤ºæ•°æ®é›†...")
        print("=" * 80)
        
        try:
            # ä½¿ç”¨æŠ€æœ¯å› å­è¡¨çš„æ•°æ®
            query = """
            SELECT 
                ts_code,
                trade_date,
                rsi_14,
                macd_dif,
                macd_dea,
                macd_histogram,
                bollinger_upper,
                bollinger_lower,
                bollinger_percent,
                stochastic_k,
                stochastic_d,
                atr_14,
                cci_14,
                williams_r,
                momentum_10,
                volume_ratio
            FROM stock_technical_factors 
            WHERE trade_date >= '2023-01-01' 
            AND trade_date <= '2023-12-31'
            ORDER BY ts_code, trade_date
            LIMIT 1000
            """
            
            df = pd.read_sql(query, self.connection)
            
            if df.empty:
                print("âŒ æœªè·å–åˆ°æŠ€æœ¯å› å­æ•°æ®")
                return None
            
            # è½¬æ¢æ•°æ®ç±»å‹
            numeric_cols = ['rsi_14', 'macd_dif', 'macd_dea', 'macd_histogram',
                           'bollinger_upper', 'bollinger_lower', 'bollinger_percent',
                           'stochastic_k', 'stochastic_d', 'atr_14', 'cci_14',
                           'williams_r', 'momentum_10', 'volume_ratio']
            
            for col in numeric_cols:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce')
            
            # åˆ é™¤åŒ…å«NaNçš„è¡Œ
            df = df.dropna()
            
            if df.empty:
                print("âŒ æ•°æ®æ¸…æ´—åä¸ºç©º")
                return None
            
            # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆæ¨¡æ‹Ÿæœªæ¥æ”¶ç›Šç‡ï¼‰
            np.random.seed(42)
            
            # åŸºäºæŠ€æœ¯æŒ‡æ ‡è®¡ç®—åŸºç¡€æ”¶ç›Šç‡
            # ä½¿ç”¨RSIã€MACDã€å¸ƒæ—çº¿ç­‰æŒ‡æ ‡çš„ç»„åˆ
            feature_weights = [0.05, 0.1, 0.1, 0.05, 0.03, 0.03, 0.15, 
                              0.08, 0.08, 0.05, 0.1, 0.08, 0.05, 0.05]
            
            # æ ‡å‡†åŒ–ç‰¹å¾
            scaler = StandardScaler()
            features_scaled = scaler.fit_transform(df[numeric_cols])
            
            # è®¡ç®—åŸºç¡€æ”¶ç›Šç‡ï¼ˆç‰¹å¾çš„çº¿æ€§ç»„åˆï¼‰
            base_returns = np.dot(features_scaled, feature_weights[:len(numeric_cols)])
            
            # æ·»åŠ éšæœºå™ªå£°
            noise = np.random.normal(0, 1.5, len(base_returns))
            df['future_return'] = base_returns + noise
            
            # å¤„ç†å¼‚å¸¸å€¼
            df = df.replace([np.inf, -np.inf], np.nan)
            df = df.fillna(df.median())
            
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
            if len(df) < 100:
                print("âŒ æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒ")
                return None
            
            print(f"âœ… æ•°æ®é›†å‡†å¤‡å®Œæˆï¼š{len(df)} æ¡è®°å½•")
            print(f"ğŸ“Š åŒ…å«è‚¡ç¥¨æ•°ï¼š{df['ts_code'].nunique()} åª")
            print(f"ğŸ“… æ—¶é—´èŒƒå›´ï¼š{df['trade_date'].min()} è‡³ {df['trade_date'].max()}")
            print(f"ğŸ“ˆ å¯ç”¨ç‰¹å¾ï¼š{len(numeric_cols)} ä¸ªæŠ€æœ¯æŒ‡æ ‡")
            
            return df
            
        except Exception as e:
            print(f"âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return None
    
    def prepare_features_and_target(self, data):
        """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
        print("\nğŸ¯ å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡...")
        
        # é€‰æ‹©æŠ€æœ¯æŒ‡æ ‡ä½œä¸ºç‰¹å¾
        feature_columns = [
            'rsi_14', 'macd_dif', 'macd_dea', 'macd_histogram',
            'bollinger_percent', 'stochastic_k', 'stochastic_d',
            'atr_14', 'cci_14', 'williams_r', 'momentum_10', 'volume_ratio'
        ]
        
        # æ£€æŸ¥ç‰¹å¾å¯ç”¨æ€§
        available_features = [col for col in feature_columns if col in data.columns]
        print(f"ğŸ“Š å¯ç”¨ç‰¹å¾æ•°é‡ï¼š{len(available_features)}")
        print(f"ğŸ“‹ ç‰¹å¾åˆ—è¡¨ï¼š{', '.join(available_features)}")
        
        if len(available_features) < 4:
            print("âŒ å¯ç”¨ç‰¹å¾å¤ªå°‘ï¼Œæ— æ³•è®­ç»ƒæ¨¡å‹")
            return None, None
        
        # å‡†å¤‡ç‰¹å¾çŸ©é˜µå’Œç›®æ ‡å˜é‡
        X = data[available_features].copy()
        y = data['future_return'].copy()
        
        # å¤„ç†å¼‚å¸¸å€¼
        X = X.replace([np.inf, -np.inf], np.nan)
        X = X.fillna(X.median())
        
        print(f"âœ… ç‰¹å¾å‡†å¤‡å®Œæˆï¼š{X.shape[0]} æ ·æœ¬ï¼Œ{X.shape[1]} ç‰¹å¾")
        print(f"ğŸ¯ ç›®æ ‡å˜é‡ç»Ÿè®¡ï¼šå‡å€¼={y.mean():.4f}ï¼Œæ ‡å‡†å·®={y.std():.4f}")
        
        return X, y
    
    def train_models(self, X, y):
        """è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
        print("\nğŸš€ å¼€å§‹æ¨¡å‹è®­ç»ƒ...")
        print("=" * 80)
        
        # æ•°æ®åˆ’åˆ†
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, shuffle=True
        )
        
        print(f"ğŸ“Š è®­ç»ƒé›†ï¼š{len(X_train)} æ ·æœ¬")
        print(f"ğŸ“Š æµ‹è¯•é›†ï¼š{len(X_test)} æ ·æœ¬")
        
        # ç‰¹å¾ç¼©æ”¾
        scaler = RobustScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        self.scalers['main'] = scaler
        
        # è®­ç»ƒå„ä¸ªæ¨¡å‹
        for model_name, model_config in self.model_configs.items():
            print(f"\nğŸ”§ è®­ç»ƒ {model_config['name']} æ¨¡å‹...")
            
            try:
                model = model_config['model']
                
                # è®­ç»ƒæ¨¡å‹
                model.fit(X_train_scaled, y_train)
                
                # é¢„æµ‹
                y_train_pred = model.predict(X_train_scaled)
                y_test_pred = model.predict(X_test_scaled)
                
                # è¯„ä¼°æŒ‡æ ‡
                train_r2 = r2_score(y_train, y_train_pred)
                test_r2 = r2_score(y_test, y_test_pred)
                train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
                test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
                train_mae = mean_absolute_error(y_train, y_train_pred)
                test_mae = mean_absolute_error(y_test, y_test_pred)
                
                # äº¤å‰éªŒè¯
                cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
                
                # ä¿å­˜æ¨¡å‹å’Œç»“æœ
                self.models[model_name] = model
                self.evaluation_results[model_name] = {
                    'train_r2': train_r2,
                    'test_r2': test_r2,
                    'train_rmse': train_rmse,
                    'test_rmse': test_rmse,
                    'train_mae': train_mae,
                    'test_mae': test_mae,
                    'cv_mean': cv_scores.mean(),
                    'cv_std': cv_scores.std(),
                    'y_train_true': y_train,
                    'y_train_pred': y_train_pred,
                    'y_test_true': y_test,
                    'y_test_pred': y_test_pred,
                    'feature_names': X.columns.tolist()
                }
                
                print(f"  âœ… è®­ç»ƒRÂ²: {train_r2:.4f}")
                print(f"  âœ… æµ‹è¯•RÂ²: {test_r2:.4f}")
                print(f"  âœ… æµ‹è¯•RMSE: {test_rmse:.4f}")
                print(f"  âœ… äº¤å‰éªŒè¯: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
                
            except Exception as e:
                print(f"  âŒ {model_config['name']} è®­ç»ƒå¤±è´¥ï¼š{e}")
        
        print(f"\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼æˆåŠŸè®­ç»ƒäº† {len(self.models)} ä¸ªæ¨¡å‹")
        
        return X_train, X_test, y_train, y_test
    
    def evaluate_and_compare_models(self):
        """è¯„ä¼°å’Œæ¯”è¾ƒæ¨¡å‹æ€§èƒ½"""
        print("\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸æ¯”è¾ƒ")
        print("=" * 80)
        
        if not self.evaluation_results:
            print("âŒ æ²¡æœ‰å¯è¯„ä¼°çš„æ¨¡å‹")
            return None, None
        
        # åˆ›å»ºè¯„ä¼°è¡¨æ ¼
        results_df = pd.DataFrame({
            model_name: {
                'è®­ç»ƒRÂ²': f"{results['train_r2']:.4f}",
                'æµ‹è¯•RÂ²': f"{results['test_r2']:.4f}",
                'æµ‹è¯•RMSE': f"{results['test_rmse']:.4f}",
                'æµ‹è¯•MAE': f"{results['test_mae']:.4f}",
                'äº¤å‰éªŒè¯å‡å€¼': f"{results['cv_mean']:.4f}",
                'äº¤å‰éªŒè¯æ ‡å‡†å·®': f"{results['cv_std']:.4f}"
            }
            for model_name, results in self.evaluation_results.items()
        }).T
        
        print("ğŸ“‹ è¯¦ç»†æ€§èƒ½æŒ‡æ ‡ï¼š")
        print(results_df.to_string())
        
        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_model_name = max(self.evaluation_results.keys(), 
                             key=lambda x: self.evaluation_results[x]['test_r2'])
        best_r2 = self.evaluation_results[best_model_name]['test_r2']
        
        print(f"\nğŸ† æœ€ä½³æ¨¡å‹ï¼š{self.model_configs[best_model_name]['name']}")
        print(f"ğŸ¯ æœ€ä½³æµ‹è¯•RÂ²ï¼š{best_r2:.4f}")
        
        return results_df, best_model_name
    
    def visualize_results(self):
        """å¯è§†åŒ–ç»“æœ"""
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        if not self.evaluation_results:
            print("âŒ æ²¡æœ‰å¯è§†åŒ–çš„æ•°æ®")
            return
        
        # åˆ›å»ºå›¾è¡¨
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('ğŸ¤– æœºå™¨å­¦ä¹ æ¨¡å‹æ€§èƒ½è¯„ä¼°ç»“æœ ğŸ¯', fontsize=16, fontweight='bold')
        
        # 1. RÂ²åˆ†æ•°æ¯”è¾ƒ
        model_names = list(self.evaluation_results.keys())
        test_r2_scores = [self.evaluation_results[name]['test_r2'] for name in model_names]
        
        bars1 = axes[0, 0].bar(model_names, test_r2_scores, color='skyblue', alpha=0.7)
        axes[0, 0].set_title('æµ‹è¯•é›†RÂ²åˆ†æ•°æ¯”è¾ƒ')
        axes[0, 0].set_ylabel('RÂ²åˆ†æ•°')
        axes[0, 0].tick_params(axis='x', rotation=45)
        axes[0, 0].grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars1, test_r2_scores):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                           f'{score:.3f}', ha='center', va='bottom', fontweight='bold')
        
        # 2. RMSEæ¯”è¾ƒ
        test_rmse_scores = [self.evaluation_results[name]['test_rmse'] for name in model_names]
        
        bars2 = axes[0, 1].bar(model_names, test_rmse_scores, color='lightcoral', alpha=0.7)
        axes[0, 1].set_title('æµ‹è¯•é›†RMSEæ¯”è¾ƒ')
        axes[0, 1].set_ylabel('RMSE')
        axes[0, 1].tick_params(axis='x', rotation=45)
        axes[0, 1].grid(axis='y', alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, score in zip(bars2, test_rmse_scores):
            axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                           f'{score:.2f}', ha='center', va='bottom', fontweight='bold')
        
        # 3. äº¤å‰éªŒè¯åˆ†æ•°
        cv_means = [self.evaluation_results[name]['cv_mean'] for name in model_names]
        cv_stds = [self.evaluation_results[name]['cv_std'] for name in model_names]
        
        bars3 = axes[0, 2].bar(model_names, cv_means, yerr=cv_stds, capsize=5, 
                              color='lightgreen', alpha=0.7)
        axes[0, 2].set_title('äº¤å‰éªŒè¯åˆ†æ•°')
        axes[0, 2].set_ylabel('CV RÂ²åˆ†æ•°')
        axes[0, 2].tick_params(axis='x', rotation=45)
        axes[0, 2].grid(axis='y', alpha=0.3)
        
        # 4. æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼ï¼ˆè®­ç»ƒé›†ï¼‰
        best_model_name = max(model_names, key=lambda x: self.evaluation_results[x]['test_r2'])
        best_results = self.evaluation_results[best_model_name]
        
        axes[1, 0].scatter(best_results['y_train_true'], best_results['y_train_pred'], 
                          alpha=0.6, color='blue', s=30)
        axes[1, 0].plot([best_results['y_train_true'].min(), best_results['y_train_true'].max()],
                       [best_results['y_train_true'].min(), best_results['y_train_true'].max()],
                       'r--', lw=2)
        axes[1, 0].set_xlabel('å®é™…æ”¶ç›Šç‡ (%)')
        axes[1, 0].set_ylabel('é¢„æµ‹æ”¶ç›Šç‡ (%)')
        axes[1, 0].set_title(f'{self.model_configs[best_model_name]["name"]} - è®­ç»ƒé›†é¢„æµ‹')
        axes[1, 0].grid(alpha=0.3)
        
        # 5. æœ€ä½³æ¨¡å‹çš„é¢„æµ‹ vs å®é™…å€¼ï¼ˆæµ‹è¯•é›†ï¼‰
        axes[1, 1].scatter(best_results['y_test_true'], best_results['y_test_pred'], 
                          alpha=0.6, color='red', s=30)
        axes[1, 1].plot([best_results['y_test_true'].min(), best_results['y_test_true'].max()],
                       [best_results['y_test_true'].min(), best_results['y_test_true'].max()],
                       'r--', lw=2)
        axes[1, 1].set_xlabel('å®é™…æ”¶ç›Šç‡ (%)')
        axes[1, 1].set_ylabel('é¢„æµ‹æ”¶ç›Šç‡ (%)')
        axes[1, 1].set_title(f'{self.model_configs[best_model_name]["name"]} - æµ‹è¯•é›†é¢„æµ‹')
        axes[1, 1].grid(alpha=0.3)
        
        # 6. ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
        if hasattr(self.models[best_model_name], 'feature_importances_'):
            importances = self.models[best_model_name].feature_importances_
            feature_names = best_results['feature_names']
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            indices = np.argsort(importances)[::-1]
            sorted_importances = importances[indices]
            sorted_features = [feature_names[i] for i in indices]
            
            bars6 = axes[1, 2].barh(range(len(sorted_features)), sorted_importances, 
                                   color='orange', alpha=0.7)
            axes[1, 2].set_yticks(range(len(sorted_features)))
            axes[1, 2].set_yticklabels(sorted_features)
            axes[1, 2].set_xlabel('ç‰¹å¾é‡è¦æ€§')
            axes[1, 2].set_title('ğŸ” æŠ€æœ¯æŒ‡æ ‡é‡è¦æ€§æ’åº')
            axes[1, 2].grid(axis='x', alpha=0.3)
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for i, (bar, importance) in enumerate(zip(bars6, sorted_importances)):
                axes[1, 2].text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,
                               f'{importance:.3f}', ha='left', va='center', fontweight='bold')
        else:
            axes[1, 2].text(0.5, 0.5, 'è¯¥æ¨¡å‹ä¸æ”¯æŒ\nç‰¹å¾é‡è¦æ€§åˆ†æ', 
                           ha='center', va='center', transform=axes[1, 2].transAxes,
                           fontsize=12)
            axes[1, 2].set_title('ç‰¹å¾é‡è¦æ€§')
        
        plt.tight_layout()
        plt.savefig('demo_ml_evaluation_results.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š å›¾è¡¨å·²ä¿å­˜ä¸º 'demo_ml_evaluation_results.png'")
        
        # æ˜¾ç¤ºå›¾è¡¨ï¼ˆåœ¨æ”¯æŒçš„ç¯å¢ƒä¸­ï¼‰
        try:
            plt.show()
        except:
            print("ğŸ“‹ æ³¨æ„ï¼šå›¾å½¢ç•Œé¢ä¸å¯ç”¨ï¼Œä½†å›¾è¡¨å·²ä¿å­˜ä¸ºæ–‡ä»¶")
    
    def generate_detailed_report(self):
        """ç”Ÿæˆè¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆè¯¦ç»†è¯„ä¼°æŠ¥å‘Š...")
        
        report = []
        report.append("=" * 100)
        report.append("ğŸ¤– è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ æ¨¡å‹ - å®Œæ•´è¯„ä¼°æŠ¥å‘Š")
        report.append("=" * 100)
        report.append(f"â° æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ğŸ“Š æ¨¡å‹ç±»å‹ï¼šåŸºäºæŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹")
        report.append("")
        
        # æ¨¡å‹æ€§èƒ½å¯¹æ¯”
        report.append("ğŸ† æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        report.append("-" * 50)
        
        for model_name, results in self.evaluation_results.items():
            model_display_name = self.model_configs[model_name]['name']
            report.append(f"ğŸ“ˆ {model_display_name}:")
            report.append(f"    è®­ç»ƒé›†RÂ²: {results['train_r2']:.4f}")
            report.append(f"    æµ‹è¯•é›†RÂ²: {results['test_r2']:.4f}")
            report.append(f"    æµ‹è¯•é›†RMSE: {results['test_rmse']:.4f}")
            report.append(f"    æµ‹è¯•é›†MAE: {results['test_mae']:.4f}")
            report.append(f"    äº¤å‰éªŒè¯: {results['cv_mean']:.4f} Â± {results['cv_std']:.4f}")
            report.append("")
        
        # æœ€ä½³æ¨¡å‹
        best_model_name = max(self.evaluation_results.keys(), 
                             key=lambda x: self.evaluation_results[x]['test_r2'])
        best_model_display = self.model_configs[best_model_name]['name']
        best_r2 = self.evaluation_results[best_model_name]['test_r2']
        
        report.append("ğŸ¯ æœ€ä½³æ¨¡å‹")
        report.append("-" * 50)
        report.append(f"ğŸ† æ¨¡å‹åç§°ï¼š{best_model_display}")
        report.append(f"ğŸ“Š æµ‹è¯•é›†RÂ²ï¼š{best_r2:.4f}")
        report.append(f"ğŸ’¡ è§£é‡Šï¼šè¯¥æ¨¡å‹èƒ½å¤Ÿè§£é‡Šçº¦ {best_r2*100:.1f}% çš„æ”¶ç›Šç‡å˜åŒ–")
        report.append("")
        
        # æ€§èƒ½åˆ†æ
        report.append("ğŸ“Š æ€§èƒ½åˆ†æ")
        report.append("-" * 50)
        if best_r2 >= 0.7:
            performance_level = "ğŸŒŸ ä¼˜ç§€"
            analysis = "æ¨¡å‹è¡¨ç°ä¼˜ç§€ï¼Œé¢„æµ‹èƒ½åŠ›å¼ºï¼Œå¯ç”¨äºå®é™…æŠ•èµ„å†³ç­–å‚è€ƒ"
        elif best_r2 >= 0.5:
            performance_level = "âœ… è‰¯å¥½"
            analysis = "æ¨¡å‹è¡¨ç°è‰¯å¥½ï¼Œæœ‰ä¸€å®šé¢„æµ‹èƒ½åŠ›ï¼Œå»ºè®®ç»“åˆå…¶ä»–æŒ‡æ ‡ä½¿ç”¨"
        elif best_r2 >= 0.3:
            performance_level = "âš ï¸ ä¸­ç­‰"
            analysis = "æ¨¡å‹è¡¨ç°ä¸­ç­‰ï¼Œå»ºè®®è°¨æ…ä½¿ç”¨å¹¶ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•"
        elif best_r2 >= 0.1:
            performance_level = "ğŸ”¶ ä¸€èˆ¬"
            analysis = "æ¨¡å‹è¡¨ç°ä¸€èˆ¬ï¼Œä¸»è¦ç”¨äºå­¦ä¹ å’Œæ¼”ç¤ºç›®çš„"
        else:
            performance_level = "âŒ è¾ƒå·®"
            analysis = "æ¨¡å‹è¡¨ç°è¾ƒå·®ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–æˆ–æ”¶é›†æ›´å¤šæ•°æ®"
        
        report.append(f"è¯„ä¼°ç­‰çº§ï¼š{performance_level}")
        report.append(f"åˆ†æç»“è®ºï¼š{analysis}")
        report.append("")
        
        # æŠ€æœ¯æŒ‡æ ‡è´¡çŒ®åº¦
        if hasattr(self.models[best_model_name], 'feature_importances_'):
            report.append("ğŸ” æŠ€æœ¯æŒ‡æ ‡è´¡çŒ®åº¦åˆ†æ")
            report.append("-" * 50)
            importances = self.models[best_model_name].feature_importances_
            feature_names = self.evaluation_results[best_model_name]['feature_names']
            
            # æ’åºç‰¹å¾é‡è¦æ€§
            sorted_indices = np.argsort(importances)[::-1]
            for i, idx in enumerate(sorted_indices[:5]):  # æ˜¾ç¤ºå‰5ä¸ªé‡è¦ç‰¹å¾
                report.append(f"  {i+1}. {feature_names[idx]}: {importances[idx]:.4f}")
            report.append("")
        
        # æ”¹è¿›å»ºè®®
        report.append("ğŸ“‹ æ”¹è¿›å»ºè®®")
        report.append("-" * 50)
        report.append("  1. å¢åŠ æ›´å¤šçš„æŠ€æœ¯æŒ‡æ ‡å’Œå¸‚åœºæ•°æ®")
        report.append("  2. è€ƒè™‘å®è§‚ç»æµæŒ‡æ ‡å’ŒåŸºæœ¬é¢æ•°æ®")
        report.append("  3. ä½¿ç”¨æ›´é•¿çš„å†å²æ•°æ®è¿›è¡Œè®­ç»ƒ")
        report.append("  4. å°è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹å’Œé›†æˆå­¦ä¹ æ–¹æ³•")
        report.append("  5. è¿›è¡Œç‰¹å¾å·¥ç¨‹å’Œæ•°æ®é¢„å¤„ç†ä¼˜åŒ–")
        report.append("  6. è€ƒè™‘æ—¶é—´åºåˆ—ç‰¹æ€§ï¼Œä½¿ç”¨LSTMç­‰åºåˆ—æ¨¡å‹")
        report.append("")
        
        # ä½¿ç”¨æ³¨æ„äº‹é¡¹
        report.append("âš ï¸ ä½¿ç”¨æ³¨æ„äº‹é¡¹")
        report.append("-" * 50)
        report.append("  1. æœ¬æ¨¡å‹åŸºäºå†å²æ•°æ®è®­ç»ƒï¼Œæ— æ³•ä¿è¯æœªæ¥æ”¶ç›Šç‡é¢„æµ‹çš„å‡†ç¡®æ€§")
        report.append("  2. è‚¡ç¥¨å¸‚åœºå…·æœ‰ä¸ç¡®å®šæ€§ï¼Œæ¨¡å‹é¢„æµ‹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®")
        report.append("  3. å»ºè®®ç»“åˆåŸºæœ¬é¢åˆ†æã€æŠ€æœ¯åˆ†æç­‰å¤šç§æ–¹æ³•è¿›è¡ŒæŠ•èµ„å†³ç­–")
        report.append("  4. å®šæœŸæ›´æ–°æ¨¡å‹è®­ç»ƒæ•°æ®ï¼Œæé«˜æ¨¡å‹çš„æ—¶æ•ˆæ€§")
        report.append("  5. æ³¨æ„é£é™©æ§åˆ¶ï¼Œé¿å…è¿‡åº¦ä¾èµ–å•ä¸€æ¨¡å‹çš„é¢„æµ‹ç»“æœ")
        report.append("  6. åœ¨å®é™…ä½¿ç”¨å‰ï¼Œå»ºè®®è¿›è¡Œæ›´é•¿æ—¶é—´çš„å›æµ‹éªŒè¯")
        report.append("")
        
        report.append("ğŸ‰ è¯„ä¼°å®Œæˆï¼æ„Ÿè°¢ä½¿ç”¨æœºå™¨å­¦ä¹ æ¨¡å‹è¯„ä¼°ç³»ç»Ÿ")
        report.append("=" * 100)
        
        # ä¿å­˜æŠ¥å‘Š
        report_text = "\n".join(report)
        with open('demo_ml_evaluation_report.txt', 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(report_text)
        print("\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜ä¸º 'demo_ml_evaluation_report.txt'")
        
        return report_text
    
    def run_complete_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„æœºå™¨å­¦ä¹ ç®¡é“"""
        print("ğŸš€ å¯åŠ¨æ¼”ç¤ºç‰ˆå®Œæ•´æœºå™¨å­¦ä¹ ç®¡é“")
        print("åŸºäºæŠ€æœ¯æŒ‡æ ‡çš„è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æ¨¡å‹æ¼”ç¤º")
        print("=" * 100)
        
        try:
            # 1. æ•°æ®å‡†å¤‡
            dataset = self.prepare_demo_dataset()
            if dataset is None:
                print("âŒ æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
                return False
            
            # 2. ç‰¹å¾å·¥ç¨‹
            X, y = self.prepare_features_and_target(dataset)
            if X is None:
                print("âŒ ç‰¹å¾å‡†å¤‡å¤±è´¥ï¼Œç»ˆæ­¢ç¨‹åº")
                return False
            
            # 3. æ¨¡å‹è®­ç»ƒ
            self.train_models(X, y)
            
            # 4. æ¨¡å‹è¯„ä¼°
            results_df, best_model = self.evaluate_and_compare_models()
            
            # 5. å¯è§†åŒ–
            self.visualize_results()
            
            # 6. ç”ŸæˆæŠ¥å‘Š
            self.generate_detailed_report()
            
            print("\nğŸ‰ å®Œæ•´æœºå™¨å­¦ä¹ ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
            print("ğŸ“Š è¯·æŸ¥çœ‹ç”Ÿæˆçš„å›¾è¡¨å’ŒæŠ¥å‘Šæ–‡ä»¶")
            print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶ï¼š")
            print("  - demo_ml_evaluation_results.png: å¯è§†åŒ–å›¾è¡¨")
            print("  - demo_ml_evaluation_report.txt: è¯¦ç»†è¯„ä¼°æŠ¥å‘Š")
            
            return True
            
        except Exception as e:
            print(f"âŒ ç®¡é“æ‰§è¡Œå¤±è´¥ï¼š{e}")
            import traceback
            traceback.print_exc()
            return False
        
        finally:
            # å…³é—­æ•°æ®åº“è¿æ¥
            if hasattr(self, 'connection'):
                self.connection.close()
                print("ğŸ”’ æ•°æ®åº“è¿æ¥å·²å…³é—­")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤– å¯åŠ¨è‚¡ç¥¨æ”¶ç›Šé¢„æµ‹æœºå™¨å­¦ä¹ ç³»ç»Ÿï¼ˆæ¼”ç¤ºç‰ˆï¼‰")
    print("åŸºäºæŠ€æœ¯æŒ‡æ ‡çš„å®Œæ•´æ¨¡å‹è®­ç»ƒä¸è¯„ä¼°")
    print("=" * 100)
    
    # åˆ›å»ºå¹¶è¿è¡Œæ¼”ç¤ºç‰ˆæ¨¡å‹
    ml_model = DemoMLModel()
    success = ml_model.run_complete_pipeline()
    
    if success:
        print("\nâœ… ç³»ç»Ÿè¿è¡ŒæˆåŠŸï¼")
        print("\nğŸŠ æ­å–œï¼æ‚¨å·²æˆåŠŸå®Œæˆæœºå™¨å­¦ä¹ æ¨¡å‹çš„å®Œæ•´è®­ç»ƒå’Œè¯„ä¼°æµç¨‹")
        print("ğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥æŸ¥çœ‹è¯¦ç»†çš„æµ‹è¯„ç»“æœï¼ŒåŒ…æ‹¬ï¼š")
        print("  ğŸ”¹ å¤šä¸ªç®—æ³•çš„æ€§èƒ½å¯¹æ¯”åˆ†æ")
        print("  ğŸ”¹ å¯è§†åŒ–çš„é¢„æµ‹æ•ˆæœå›¾è¡¨")
        print("  ğŸ”¹ æŠ€æœ¯æŒ‡æ ‡é‡è¦æ€§åˆ†æ")
        print("  ğŸ”¹ è¯¦ç»†çš„è¯„ä¼°æŠ¥å‘Šå’Œå»ºè®®")
        print("\nğŸ“ˆ è¿™ä¸ªå®Œæ•´çš„æœºå™¨å­¦ä¹ ç³»ç»Ÿå±•ç¤ºäº†ä»æ•°æ®å‡†å¤‡åˆ°æ¨¡å‹è¯„ä¼°çš„å…¨æµç¨‹ï¼")
        print("ğŸ”¥ æ‚¨ç°åœ¨æ‹¥æœ‰äº†ä¸€ä¸ªå¯ä»¥è¿è¡Œçš„è‚¡ç¥¨é¢„æµ‹æ¨¡å‹ï¼")
    else:
        print("\nâŒ ç³»ç»Ÿè¿è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 